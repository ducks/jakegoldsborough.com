<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="fediverse:creator" content="@ducks@hachyderm.io">
    <link rel="me" href="https://hachyderm.io/@ducks" />
    <meta name="author" content="Jake Goldsborough">

    <link rel="preload" href="https://jakegoldsborough.com/fonts/berkeley-mono/BerkeleyMono-Regular.woff2" as="font" type="font/woff2" crossorigin>
    <link rel="preload" href="https://jakegoldsborough.com/fonts/waika/waika-webfont.woff2" as="font" type="font/woff2" crossorigin>
    
    <meta name="description" content="Declarative multi-step pipelines and Ollama integration. The workflow system that&#x27;s also a plugin system.">
    <meta name="keywords" content="NixOS, Linux, Rust, self-hosting, programming, tech blog, OSS">

    
    <meta property="og:site_name" content="Jake Goldsborough">
    <meta property="og:title" content="Lok Part 2: Workflows and Local LLMs">
    <meta property="og:description" content="Declarative multi-step pipelines and Ollama integration. The workflow system that&#x27;s also a plugin system.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;lok-workflows-and-local-llms&#x2F;">

    
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Lok Part 2: Workflows and Local LLMs">
    <meta name="twitter:description" content="Declarative multi-step pipelines and Ollama integration. The workflow system that&#x27;s also a plugin system.">

    <title>Lok Part 2: Workflows and Local LLMs - Jake Goldsborough</title>

    <link rel="stylesheet" href="https://jakegoldsborough.com/css/style.css" />

    
    <link rel="icon" href="https://jakegoldsborough.com/images/favicon.png" />
  </head>
  <body>
    <header>
      
        <h1><a href="https://jakegoldsborough.com">Jake Goldsborough</a></h1>
      

      <input type="checkbox" id="menu-toggle" class="menu-toggle" />
      <label for="menu-toggle" class="hamburger">
        <span></span>
        <span></span>
        <span></span>
      </label>

      <nav>
        <a
          href="https://jakegoldsborough.com/blog"
          class="active"
        >Blog</a>
        <a
          href="https://jakegoldsborough.com/resume"
          class=""
          >Resume</a>
        <a
          href="https://jakegoldsborough.com/projects"
          class=""
          >Projects</a>
        <a
          href="https://jakegoldsborough.com/contact"
          class=""
          >Contact</a>
      </nav>
    </header>
    <main>
      
  
    <article>
      <h1>Lok Part 2: Workflows and Local LLMs</h1>
      <div class="meta">
        
        <p>Jan 25, 2026</p>
        
        <p>5 min read</p>
      </div>

      
        <div class="tags">
          
          <p><a href="/tags/ai">#ai</a></p>
          
          <p><a href="/tags/tools">#tools</a></p>
          
          <p><a href="/tags/rust">#rust</a></p>
          
          <p><a href="/tags/dev">#dev</a></p>
          
        </div>
      

      <p>Since <a href="/blog/2026/introducing-lok-multi-llm-orchestration/">introducing Lok</a>, two
features emerged from actual use: local LLM support via Ollama, and a declarative
workflow engine. Both solve real problems I hit while using the tool.</p>
<h2 id="ollama-local-llms-without-the-api-tax">Ollama: Local LLMs Without the API Tax</h2>
<p>Cloud APIs are great until they're not. Rate limits, quota exhaustion, latency
spikes, privacy concerns. Sometimes you just want to run a model locally and not
worry about any of that.</p>
<p>Ollama runs LLMs on your machine via a simple HTTP API. Lok now supports it as a
first-class backend:</p>
<pre data-lang="toml" style="background-color:#2b303b;color:#c0c5ce;" class="language-toml "><code class="language-toml" data-lang="toml"><span style="color:#65737e;"># ~/.config/lok/lok.toml
</span><span>[backends.ollama]
</span><span style="color:#bf616a;">enabled </span><span>= </span><span style="color:#d08770;">true
</span><span style="color:#bf616a;">command </span><span>= &quot;</span><span style="color:#a3be8c;">http://localhost:11434</span><span>&quot;
</span><span style="color:#bf616a;">model </span><span>= &quot;</span><span style="color:#a3be8c;">llama3.2</span><span>&quot;
</span></code></pre>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">lok</span><span> ask</span><span style="color:#bf616a;"> --backend</span><span> ollama &quot;</span><span style="color:#a3be8c;">Explain this function</span><span>&quot;
</span></code></pre>
<p>The implementation is straightforward. Ollama exposes a <code>/api/chat</code> endpoint that
accepts JSON. No CLI binary to shell out to, no stdout parsing. Just HTTP.</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span>async </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">chat</span><span>(&amp;</span><span style="color:#bf616a;">self</span><span>, </span><span style="color:#bf616a;">prompt</span><span>: &amp;</span><span style="color:#b48ead;">str</span><span>) -&gt; Result&lt;String&gt; {
</span><span>    </span><span style="color:#b48ead;">let</span><span> request = ChatRequest {
</span><span>        model: </span><span style="color:#bf616a;">self</span><span>.model.</span><span style="color:#96b5b4;">clone</span><span>(),
</span><span>        messages: vec![ChatMessage {
</span><span>            role: &quot;</span><span style="color:#a3be8c;">user</span><span>&quot;.</span><span style="color:#96b5b4;">to_string</span><span>(),
</span><span>            content: prompt.</span><span style="color:#96b5b4;">to_string</span><span>(),
</span><span>        }],
</span><span>        stream: </span><span style="color:#d08770;">false</span><span>,
</span><span>    };
</span><span>
</span><span>    </span><span style="color:#b48ead;">let</span><span> response = </span><span style="color:#bf616a;">self</span><span>.client
</span><span>        .</span><span style="color:#96b5b4;">post</span><span>(format!(&quot;</span><span style="color:#d08770;">{}</span><span style="color:#a3be8c;">/api/chat</span><span>&quot;, </span><span style="color:#bf616a;">self</span><span>.base_url))
</span><span>        .</span><span style="color:#96b5b4;">json</span><span>(&amp;request)
</span><span>        .</span><span style="color:#96b5b4;">send</span><span>()
</span><span>        .await?;
</span><span>
</span><span>    </span><span style="color:#65737e;">// Parse response...
</span><span>}
</span></code></pre>
<p><strong>When to use Ollama:</strong></p>
<ul>
<li>Privacy-sensitive codebases that can't hit external APIs</li>
<li>Avoiding rate limits during intensive analysis sessions</li>
<li>Cost control (no per-token billing)</li>
<li>Offline development environments</li>
</ul>
<p><strong>Trade-offs:</strong></p>
<ul>
<li>Slower than cloud APIs on most hardware</li>
<li>Model quality depends on what you can run locally</li>
<li>Requires Ollama running as a daemon</li>
</ul>
<p>In practice, I use Ollama for synthesis steps where I'm combining outputs from
faster cloud models. The final summarization doesn't need to be fast, it needs
to be private and reliable.</p>
<h2 id="workflows-declarative-multi-step-pipelines">Workflows: Declarative Multi-Step Pipelines</h2>
<p>Single-shot LLM calls are useful, but real analysis often requires multiple
passes. First a fast scan, then a deep investigation, then synthesis. Doing this
manually means copy-pasting outputs between commands.</p>
<p>Workflows solve this by defining multi-step pipelines in TOML:</p>
<pre data-lang="toml" style="background-color:#2b303b;color:#c0c5ce;" class="language-toml "><code class="language-toml" data-lang="toml"><span style="color:#65737e;"># ~/.config/lok/workflows/security-review.toml
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">security-review</span><span>&quot;
</span><span style="color:#bf616a;">description </span><span>= &quot;</span><span style="color:#a3be8c;">Multi-pass security review with synthesis</span><span>&quot;
</span><span>
</span><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">initial-scan</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">codex</span><span>&quot;
</span><span style="color:#bf616a;">prompt </span><span>= &quot;</span><span style="color:#a3be8c;">Find obvious security issues: injection, auth bypass, hardcoded secrets</span><span>&quot;
</span><span>
</span><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">deep-audit</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">claude</span><span>&quot;
</span><span style="color:#bf616a;">depends_on </span><span>= [&quot;</span><span style="color:#a3be8c;">initial-scan</span><span>&quot;]
</span><span style="color:#bf616a;">prompt </span><span>= &quot;&quot;&quot;
</span><span style="color:#a3be8c;">Review these findings and investigate deeper:
</span><span style="color:#a3be8c;">{{ steps.initial-scan.output }}
</span><span>&quot;&quot;&quot;
</span><span>
</span><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">synthesize</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">ollama</span><span>&quot;
</span><span style="color:#bf616a;">depends_on </span><span>= [&quot;</span><span style="color:#a3be8c;">initial-scan</span><span>&quot;, &quot;</span><span style="color:#a3be8c;">deep-audit</span><span>&quot;]
</span><span style="color:#bf616a;">prompt </span><span>= &quot;&quot;&quot;
</span><span style="color:#a3be8c;">Combine into a prioritized report:
</span><span style="color:#a3be8c;">Initial: {{ steps.initial-scan.output }}
</span><span style="color:#a3be8c;">Deep: {{ steps.deep-audit.output }}
</span><span>&quot;&quot;&quot;
</span></code></pre>
<p>Run it with:</p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">lok</span><span> run security-review
</span></code></pre>
<p>The output:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Running workflow: security-review
</span><span>Multi-pass security review with synthesis
</span><span>==================================================
</span><span>
</span><span>[step] initial-scan
</span><span>  ✓ (2.3s)
</span><span>[step] deep-audit
</span><span>  ✓ (8.1s)
</span><span>[step] synthesize
</span><span>  ✓ (4.2s)
</span><span>
</span><span>==================================================
</span><span>
</span><span>Results:
</span><span>
</span><span>[OK] initial-scan (2.3s)
</span><span>
</span><span>  Found 5 potential issues:
</span><span>  1. src/api/auth.rs:45 - SQL string interpolation
</span><span>  ...
</span><span>
</span><span>[OK] deep-audit (8.1s)
</span><span>
</span><span>  Investigated the SQL interpolation finding...
</span><span>  ...
</span><span>
</span><span>[OK] synthesize (4.2s)
</span><span>
</span><span>  ## Security Review Summary
</span><span>
</span><span>  ### Critical (1)
</span><span>  - SQL injection in auth.rs...
</span></code></pre>
<h3 id="variable-interpolation">Variable Interpolation</h3>
<p>The <code>{{ steps.NAME.output }}</code> syntax passes previous step outputs into subsequent
prompts. The workflow engine does a simple regex replacement before sending the
prompt to the backend.</p>
<p>This is the key feature that makes workflows useful. Without it, you'd need
manual copy-paste between steps. With it, you can build arbitrary pipelines
where each step builds on previous results.</p>
<h3 id="dependency-resolution">Dependency Resolution</h3>
<p>Steps declare dependencies with <code>depends_on</code>. The engine performs a topological
sort to determine execution order. Steps without dependencies can run in
parallel (though the current implementation runs sequentially for simplicity).</p>
<pre data-lang="toml" style="background-color:#2b303b;color:#c0c5ce;" class="language-toml "><code class="language-toml" data-lang="toml"><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">patterns</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">codex</span><span>&quot;
</span><span style="color:#bf616a;">prompt </span><span>= &quot;</span><span style="color:#a3be8c;">Find code patterns</span><span>&quot;
</span><span>
</span><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">dead-code</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">codex</span><span>&quot;
</span><span style="color:#bf616a;">prompt </span><span>= &quot;</span><span style="color:#a3be8c;">Find dead code</span><span>&quot;
</span><span>
</span><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">synthesize</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">claude</span><span>&quot;
</span><span style="color:#bf616a;">depends_on </span><span>= [&quot;</span><span style="color:#a3be8c;">patterns</span><span>&quot;, &quot;</span><span style="color:#a3be8c;">dead-code</span><span>&quot;]
</span><span style="color:#bf616a;">prompt </span><span>= &quot;&quot;&quot;
</span><span style="color:#a3be8c;">Combine findings:
</span><span style="color:#a3be8c;">Patterns: {{ steps.patterns.output }}
</span><span style="color:#a3be8c;">Dead code: {{ steps.dead-code.output }}
</span><span>&quot;&quot;&quot;
</span></code></pre>
<p>The first two steps have no dependencies, so they could run concurrently. The
third step waits for both to complete before running.</p>
<h3 id="conditional-execution">Conditional Execution</h3>
<p>Steps can include a <code>when</code> clause for conditional execution:</p>
<pre data-lang="toml" style="background-color:#2b303b;color:#c0c5ce;" class="language-toml "><code class="language-toml" data-lang="toml"><span>[[steps]]
</span><span style="color:#bf616a;">name </span><span>= &quot;</span><span style="color:#a3be8c;">emergency-fix</span><span>&quot;
</span><span style="color:#bf616a;">backend </span><span>= &quot;</span><span style="color:#a3be8c;">claude</span><span>&quot;
</span><span style="color:#bf616a;">depends_on </span><span>= [&quot;</span><span style="color:#a3be8c;">scan</span><span>&quot;]
</span><span style="color:#bf616a;">when </span><span>= &quot;</span><span style="color:#a3be8c;">steps.scan.output contains &#39;critical&#39;</span><span>&quot;
</span><span style="color:#bf616a;">prompt </span><span>= &quot;</span><span style="color:#a3be8c;">Propose immediate fixes for critical issues...</span><span>&quot;
</span></code></pre>
<p>If the condition isn't met, the step is skipped with a <code>[skip]</code> message. This
keeps workflows from doing unnecessary work.</p>
<h3 id="workflow-discovery">Workflow Discovery</h3>
<p>Workflows are loaded from two locations:</p>
<ul>
<li><code>.lok/workflows/</code> in the current directory (project-local)</li>
<li><code>~/.config/lok/workflows/</code> (global)</li>
</ul>
<p>Project-local workflows override global ones with the same name. This lets you
define team-wide workflows globally while allowing project-specific overrides.</p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">lok</span><span> workflow list
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Available workflows:
</span><span>
</span><span>  security-review (global)
</span><span>    Multi-pass security review with synthesis
</span><span>    3 steps
</span><span>
</span><span>  code-quality (global)
</span><span>    Multi-backend code quality analysis
</span><span>    3 steps
</span><span>
</span><span>  rails-audit (local)
</span><span>    Rails-specific security checks
</span><span>    4 steps
</span></code></pre>
<h2 id="the-plugin-system-realization">The Plugin System Realization</h2>
<p>Here's the thing I didn't plan: workflows are plugins.</p>
<p>When you define a workflow, you're creating a reusable command. <code>lok run security-review</code> isn't calling a built-in feature. It's loading a TOML file and
executing it. The "plugin" is just configuration.</p>
<p>This means:</p>
<ul>
<li>No compilation needed to add new capabilities</li>
<li>Share workflows by copying TOML files</li>
<li>Customize existing workflows without touching Rust code</li>
<li>Version control your workflows alongside your code</li>
</ul>
<p>A future <code>lok workflow install</code> could fetch workflows from URLs:</p>
<pre data-lang="bash" style="background-color:#2b303b;color:#c0c5ce;" class="language-bash "><code class="language-bash" data-lang="bash"><span style="color:#bf616a;">lok</span><span> workflow install https://example.com/rails-audit.toml
</span><span style="color:#bf616a;">lok</span><span> run rails-audit
</span></code></pre>
<p>The plugin system is the workflow system. No separate concepts needed.</p>
<h2 id="the-real-conductor-your-llm-session">The Real Conductor: Your LLM Session</h2>
<p>Here's the pattern that actually works best: use your existing LLM as the
conductor, and call lok as a tool.</p>
<p>I run Claude Code as my daily driver. When I need multi-model analysis, I don't
switch to <code>lok conduct</code>. I just ask Claude to use lok:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Me: Find performance issues in this codebase
</span><span>
</span><span>Claude: [runs: lok ask --backend codex &quot;Find N+1 queries and performance issues&quot;]
</span><span>
</span><span>Claude: I found 3 N+1 queries in the controllers. Let me get a second
</span><span>        opinion on the caching strategy...
</span><span>
</span><span>Claude: [runs: lok ask --backend gemini &quot;Review caching approach in lib/cache.rb&quot;]
</span><span>
</span><span>Claude: Based on both analyses, here&#39;s what I&#39;d prioritize...
</span></code></pre>
<p>The LLM session becomes the orchestration layer. It sees results, reasons about
them, decides when to query other backends. No need for lok to implement its own
multi-round conversation loop.</p>
<p>This works because lok is just a command. It doesn't try to be a chat interface
or maintain conversation state. It does one thing: send a prompt to backends and
return results. The intelligence stays in the LLM that's already running.</p>
<p>The workflow engine complements this. For repeatable multi-step analysis, define
a workflow. For exploratory work where you need to reason about intermediate
results, let your LLM call lok directly.</p>
<h2 id="putting-it-together">Putting It Together</h2>
<p>Here's my actual workflow for auditing a new codebase:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Me: Audit this codebase for security issues
</span><span>
</span><span>Claude: [runs: lok run security-review]
</span><span>
</span><span>Claude: The workflow found 5 issues. The SQL interpolation in auth.rs
</span><span>        looks serious. Let me investigate...
</span><span>
</span><span>Claude: [runs: lok ask --backend gemini &quot;Is the SQL in auth.rs:45 exploitable?&quot;]
</span><span>
</span><span>Claude: Gemini confirms it&#39;s exploitable. I&#39;ll draft a fix...
</span></code></pre>
<p>Workflows handle the repeatable multi-step analysis. Claude handles the
reasoning and follow-up questions. Lok is just the interface to multiple
backends. Each layer does what it's good at.</p>
<h2 id="what-s-next">What's Next</h2>
<p>The dead code that <code>lok hunt</code> found in its own codebase still needs cleanup.
There's also the question of parallel step execution in workflows, which would
make multi-backend pipelines faster.</p>
<p>But the core loop is solid: define workflows in TOML, run them with one command,
get multi-model analysis without the manual coordination tax.</p>
<p>The source is at <a href="https://github.com/ducks/lok">github.com/ducks/lok</a>.</p>
<hr />
<p>Previous: <a href="/blog/2026/introducing-lok-multi-llm-orchestration">Introducing Lok</a> |
Next: <a href="/blog/2026/lok-dogfooding-and-code-review">Part 3: Dogfooding and Code Review</a></p>


      
        
        

        
          
            
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
        

        
          <section class="related-posts">
            <h2>Related Posts</h2>
            <ul class="blog-posts">
              
                <li class="post-item">
                  <h3><a href="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;ai-problems-are-human-problems&#x2F;">AI Problems Are Just Human Problems Amplified</a></h3>
                  <div class="meta">
                    
                    <p>Feb 23, 2026</p>
                    
                    <p>6 min read</p>
                  </div>
                  
                    <p class="desc">AI fatigue, perfectionism vs non-determinism, and garbage in&#x2F;garbage out. These are not new problems. AI just makes them obvious faster.</p>
                  
                  
                    <div class="tags">
                      
                      <p><a href="/tags/ai">#ai</a></p>
                      
                      <p><a href="/tags/tools">#tools</a></p>
                      
                      <p><a href="/tags/dev">#dev</a></p>
                      
                    </div>
                  
                  <div class="squiqqle-line"></div>
                </li>
              
                <li class="post-item">
                  <h3><a href="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;llm-mux-workflow-orchestration&#x2F;">llm-mux: Why I Rebuilt Lok</a></h3>
                  <div class="meta">
                    
                    <p>Feb 11, 2026</p>
                    
                    <p>3 min read</p>
                  </div>
                  
                    <p class="desc">Lok got 300+ installs, then I rewrote it. The abstractions were wrong. llm-mux has roles, teams, and proper apply&#x2F;verify. Here&#x27;s why.</p>
                  
                  
                    <div class="tags">
                      
                      <p><a href="/tags/ai">#ai</a></p>
                      
                      <p><a href="/tags/tools">#tools</a></p>
                      
                      <p><a href="/tags/rust">#rust</a></p>
                      
                      <p><a href="/tags/dev">#dev</a></p>
                      
                    </div>
                  
                  <div class="squiqqle-line"></div>
                </li>
              
                <li class="post-item">
                  <h3><a href="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;finna-multi-model-spec-implement&#x2F;">finna: Multi-Model Debate, Spec, and Implement</a></h3>
                  <div class="meta">
                    
                    <p>Feb 10, 2026</p>
                    
                    <p>5 min read</p>
                  </div>
                  
                    <p class="desc">A standalone tool that takes an idea, debates it across Claude, Codex, and Gemini, creates a roadmap, writes specs, and implements. Planning and execution in one pipeline.</p>
                  
                  
                    <div class="tags">
                      
                      <p><a href="/tags/ai">#ai</a></p>
                      
                      <p><a href="/tags/tools">#tools</a></p>
                      
                      <p><a href="/tags/rust">#rust</a></p>
                      
                      <p><a href="/tags/dev">#dev</a></p>
                      
                    </div>
                  
                  <div class="squiqqle-line"></div>
                </li>
              
                <li class="post-item">
                  <h3><a href="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;lok-json-parser-multi-llm&#x2F;">Building a JSON Parser with Multi-LLM Orchestration (Part 1)</a></h3>
                  <div class="meta">
                    
                    <p>Feb 07, 2026</p>
                    
                    <p>3 min read</p>
                  </div>
                  
                    <p class="desc">Using lok to orchestrate four LLMs debating design decisions, then synthesizing specs for a Rust JSON parser. The debate phase surfaced edge cases no single model would have caught.</p>
                  
                  
                    <div class="tags">
                      
                      <p><a href="/tags/ai">#ai</a></p>
                      
                      <p><a href="/tags/tools">#tools</a></p>
                      
                      <p><a href="/tags/rust">#rust</a></p>
                      
                      <p><a href="/tags/dev">#dev</a></p>
                      
                    </div>
                  
                  <div class="squiqqle-line"></div>
                </li>
              
                <li class="post-item">
                  <h3><a href="https:&#x2F;&#x2F;jakegoldsborough.com&#x2F;blog&#x2F;2026&#x2F;lok-spec-multi-agent-planning&#x2F;">Lok Part 5: Multi-Agent Planning with lok spec</a></h3>
                  <div class="meta">
                    
                    <p>Feb 06, 2026</p>
                    
                    <p>6 min read</p>
                  </div>
                  
                    <p class="desc">Lok gains a spec command that turns task descriptions into structured implementation plans. Multiple LLMs propose, debate, and converge on a roadmap before any code gets written.</p>
                  
                  
                    <div class="tags">
                      
                      <p><a href="/tags/ai">#ai</a></p>
                      
                      <p><a href="/tags/tools">#tools</a></p>
                      
                      <p><a href="/tags/rust">#rust</a></p>
                      
                      <p><a href="/tags/dev">#dev</a></p>
                      
                    </div>
                  
                  <div class="squiqqle-line"></div>
                </li>
              
            </ul>
          </section>
        
      
    </article>
  

    </main>

    <footer>
      <p><a href="https://jakegoldsborough.com/rss.xml">Subscribe via RSS</a></p>
    </footer>

    <script src="/js/main.js"></script>
    <script data-goatcounter="https://stats.jakegoldsborough.com/count"
        async src="//stats.jakegoldsborough.com/count.js"></script>
  </body>
</html>

