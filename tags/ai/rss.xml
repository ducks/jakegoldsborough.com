<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
      <title>Jake Goldsborough - ai</title>
      <link>https://jakegoldsborough.com</link>
      <description></description>
      <generator>Zola</generator>
      <language>en</language>
      <atom:link href="https://jakegoldsborough.com/tags/ai/rss.xml" rel="self" type="application/rss+xml"/>
      <lastBuildDate>Mon, 23 Feb 2026 00:00:00 +0000</lastBuildDate>
      <item>
          <title>AI Problems Are Just Human Problems Amplified</title>
          <pubDate>Mon, 23 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/ai-problems-are-human-problems/</link>
          <guid>https://jakegoldsborough.com/blog/2026/ai-problems-are-human-problems/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/ai-problems-are-human-problems/">&lt;p&gt;Another day, another article about AI fatigue and all the other problems it
causes. And I agree, the symptoms are real: burnout from keeping up with new
models, FOMO about missing capabilities, perfectionism about getting prompts
exactly right, analysis paralysis about which tool to use.&lt;&#x2F;p&gt;
&lt;p&gt;However, I do not think these are new problems. Developers burned out keeping
up with JavaScript frameworks before AI existed. FOMO about missing the next
big thing has been around since the first tech conference. Perfectionism about
tooling choices is why we have 47 different React state management libraries.&lt;&#x2F;p&gt;
&lt;p&gt;AI did not create these problems. It amplified them. New models ship every
month instead of every year. The output quality depends heavily on prompt
engineering, so perfectionism has visible consequences. The tooling landscape
changes so fast that yesterday&#x27;s best practice is tomorrow&#x27;s deprecated
approach.&lt;&#x2F;p&gt;
&lt;p&gt;The solution is the same as it always was: pick something, build with it, move
on. If the tool does not work, try a different one. If the output is wrong, fix
the prompt or fix the output. Stop trying to find the perfect model, the
perfect prompt, the perfect workflow. There is no perfect. There is only good
enough to ship.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;garbage-in-garbage-out&quot;&gt;Garbage In, Garbage Out&lt;&#x2F;h2&gt;
&lt;p&gt;I spent yesterday implementing a Rails app called Webstead using a multi-model
code generation tool called finna. The tool works like this: multiple LLMs
debate the architecture, synthesize a consensus, generate specs, then implement
the code.&lt;&#x2F;p&gt;
&lt;p&gt;The tool generated migrations with circular dependencies. The &lt;code&gt;CreateUsers&lt;&#x2F;code&gt;
migration referenced &lt;code&gt;websteads&lt;&#x2F;code&gt; that did not exist yet. The &lt;code&gt;CreateWebsteads&lt;&#x2F;code&gt;
migration referenced &lt;code&gt;users&lt;&#x2F;code&gt; that did not exist yet. The &lt;code&gt;CreateFollowers&lt;&#x2F;code&gt;
migration referenced &lt;code&gt;federated_actors&lt;&#x2F;code&gt; with a timestamp 204514 instead of the
correct 000003.&lt;&#x2F;p&gt;
&lt;p&gt;The models also added duplicate indexes, self-referential foreign keys that
caused deadlocks, and CHECK constraints that hung the migration runner.&lt;&#x2F;p&gt;
&lt;p&gt;Was this an AI problem? No. It was a coordination problem. The models generated
migrations independently without seeing what the other models had created.
Dependencies got misordered. Constraints conflicted. The tool did not validate
that migrations could actually run before writing them to disk.&lt;&#x2F;p&gt;
&lt;p&gt;The fix was not better AI. The fix was better constraints. Migrations need
dependency ordering. The tool needs to number them sequentially. If a migration
references a table, that table&#x27;s migration must run first.&lt;&#x2F;p&gt;
&lt;p&gt;This is the same coordination problem human developers face on multi-person
teams. You just notice it faster when the team is four LLMs running in
parallel.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-actually-works&quot;&gt;What Actually Works&lt;&#x2F;h2&gt;
&lt;p&gt;I use AI for code generation daily. Here is what works:&lt;&#x2F;p&gt;
&lt;p&gt;Use it for tasks with clear specifications. If you can describe the desired
output precisely, the model will probably generate something close. If you
cannot describe what you want, the model will not guess correctly.&lt;&#x2F;p&gt;
&lt;p&gt;Review the output. The model will make mistakes. It will use deprecated APIs.
It will skip edge cases. It will generate code that compiles but does not work.
Treat it like code review from a junior developer who types fast but does not
check their work.&lt;&#x2F;p&gt;
&lt;p&gt;Iterate on the prompt when the output is wrong. If it generates migrations with
circular dependencies, tell it to output migrations in dependency order. The
model does not know your requirements unless you tell it.&lt;&#x2F;p&gt;
&lt;p&gt;Use multiple models when the task is ambiguous. Different models have different
blind spots. One model catches precision bugs in number handling. Another
catches stack overflow vulnerabilities in recursive parsers. Consensus finds
edge cases no single model would have caught.&lt;&#x2F;p&gt;
&lt;p&gt;Do not expect the model to read your mind. It cannot. It is text prediction,
not telepathy.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-real-problem&quot;&gt;The Real Problem&lt;&#x2F;h2&gt;
&lt;p&gt;The real problem with AI tools is that people expect them to solve problems
humans have not solved yet.&lt;&#x2F;p&gt;
&lt;p&gt;You cannot ask an AI to follow code style if you have not documented the style.
You cannot ask it to implement a feature if you have not specified what the
feature should do.&lt;&#x2F;p&gt;
&lt;p&gt;AI does not eliminate the need for clear requirements, documentation, or code
review. It amplifies the cost of not having them. If your team does not have
coding standards, the AI will generate code in 47 different styles. If your
project does not have tests, the AI will break things you did not know were
fragile. If your specs are ambiguous, the AI will pick the wrong interpretation.&lt;&#x2F;p&gt;
&lt;p&gt;This is not the AI&#x27;s fault. This is your fault for not having standards, tests,
or specs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;using-ai-without-losing-your-mind&quot;&gt;Using AI Without Losing Your Mind&lt;&#x2F;h2&gt;
&lt;p&gt;Here is what I do:&lt;&#x2F;p&gt;
&lt;p&gt;Treat AI as a tool, not a coworker. It does not understand context. It does not
remember what you said three prompts ago. It does not know what you meant
versus what you typed. Give it explicit instructions and check the output.&lt;&#x2F;p&gt;
&lt;p&gt;Use it for tasks with high certainty and low blast radius. Generating test
cases? Great. Refactoring variable names? Fine. Rewriting your entire database
layer? Probably not.&lt;&#x2F;p&gt;
&lt;p&gt;Keep humans in the loop at decision boundaries. Generate the plan, review it,
then execute. Generate the code, review it, then merge. The AI can propose. You
decide.&lt;&#x2F;p&gt;
&lt;p&gt;Do not try to keep up with every new model. Pick one that works and use it
until it does not work anymore. Switching models every week is how you burn
out.&lt;&#x2F;p&gt;
&lt;p&gt;Lower your expectations. The AI will not write production-ready code from a
vague prompt. It will write something that compiles and mostly works. You fix
the rest. That is still faster than writing it yourself from scratch.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;p&gt;AI problems are human problems. Burnout from keeping up with too many tools.
FOMO about missing the next breakthrough. Perfectionism about getting it
exactly right. Analysis paralysis about which approach to take. Garbage in,
garbage out.&lt;&#x2F;p&gt;
&lt;p&gt;We had these problems before AI. We will have these problems after AI. The only
difference is speed. AI makes bad processes fail faster. It makes unclear
requirements obvious immediately. It makes poor documentation expensive in
minutes instead of months.&lt;&#x2F;p&gt;
&lt;p&gt;If you are struggling with AI tools, the problem is probably not the AI. The
problem is that your process, documentation, or requirements were already
broken. AI just made it obvious.&lt;&#x2F;p&gt;
&lt;p&gt;Fix the process. The AI will follow.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>llm-mux: Why I Rebuilt Lok</title>
          <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/llm-mux-workflow-orchestration/</link>
          <guid>https://jakegoldsborough.com/blog/2026/llm-mux-workflow-orchestration/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/llm-mux-workflow-orchestration/">&lt;p&gt;Lok hit 317 cargo installs. People were using it. So naturally I rewrote it from
scratch.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s not as chaotic as it sounds. Lok grew organically from &quot;query multiple
LLMs&quot; to &quot;run workflows&quot; to &quot;apply edits&quot; to &quot;create GitHub issues.&quot; Each feature
bolted onto the side. The codebase worked but the abstractions were wrong.&lt;&#x2F;p&gt;
&lt;p&gt;llm-mux is what lok should have been from the start.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-was-wrong&quot;&gt;What Was Wrong&lt;&#x2F;h2&gt;
&lt;p&gt;Lok conflates backends with tasks. When you write &lt;code&gt;backend = &quot;claude&quot;&lt;&#x2F;code&gt; in a
workflow step, you&#x27;re coupling your workflow to a specific model. Want to swap
Claude for Gemini? Edit every step.&lt;&#x2F;p&gt;
&lt;p&gt;Lok also has no concept of project context. A Rust project needs &lt;code&gt;cargo test&lt;&#x2F;code&gt;
for verification. A Node project needs &lt;code&gt;npm test&lt;&#x2F;code&gt;. In lok, you hardcode these
per-workflow. Switch projects, rewrite workflows.&lt;&#x2F;p&gt;
&lt;p&gt;The apply_edits feature was bolted on late. It works but there&#x27;s no retry loop,
no structured verification, no rollback without git-agent.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;roles&quot;&gt;Roles&lt;&#x2F;h2&gt;
&lt;p&gt;llm-mux introduces roles. Instead of hardcoding backends:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# lok style - backend hardcoded
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;analyze&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find bugs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;You declare what kind of task it is:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# llm-mux style - role-based
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;analyze&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;type &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;query&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;role &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;analyzer&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find bugs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then configure which backends handle which roles:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[roles.analyzer]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Code analysis tasks&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backends &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;execution &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;parallel&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[roles.quick]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Fast local checks&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backends &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;qwen&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;execution &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;first&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Swapping backends is a config change, not a workflow rewrite. The workflow says
&quot;I need analysis.&quot; The config decides who does analysis.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;teams&quot;&gt;Teams&lt;&#x2F;h2&gt;
&lt;p&gt;Teams add project context:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[teams.rust]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Rust projects&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;detect &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Cargo.toml&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;verify &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;cargo clippy &amp;amp;&amp;amp; cargo test&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[teams.rust.roles.analyzer]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backends &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When llm-mux detects &lt;code&gt;Cargo.toml&lt;&#x2F;code&gt;, it activates the rust team. Verification
commands come from the team. Role mappings can be overridden per-team.&lt;&#x2F;p&gt;
&lt;p&gt;Same workflow, different projects, correct tooling.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;http-backends&quot;&gt;HTTP Backends&lt;&#x2F;h2&gt;
&lt;p&gt;Lok only does CLI. You shell out to &lt;code&gt;claude&lt;&#x2F;code&gt;, &lt;code&gt;codex&lt;&#x2F;code&gt;, &lt;code&gt;ollama run&lt;&#x2F;code&gt;. Each query
spawns a process.&lt;&#x2F;p&gt;
&lt;p&gt;llm-mux supports both CLI and HTTP:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[backends.claude]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;command &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;args &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;-p&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;--&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[backends.openai]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;command &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;https:&#x2F;&#x2F;api.openai.com&#x2F;v1&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;gpt-4&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;api_key &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;${OPENAI_API_KEY}&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[backends.local]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;command &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;http:&#x2F;&#x2F;localhost:11434&#x2F;v1&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;llama3&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If the command starts with &lt;code&gt;http&lt;&#x2F;code&gt;, it&#x27;s HTTP. Otherwise CLI. HTTP is faster for
high-volume workflows. No process overhead. Proper streaming. Rate limit handling.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;apply-and-verify&quot;&gt;Apply and Verify&lt;&#x2F;h2&gt;
&lt;p&gt;Lok&#x27;s apply_edits was a boolean flag. llm-mux has a real system:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;fix&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;type &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;apply&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;source &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;steps.analyze&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;verify &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;cargo test&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;verify_retries &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;3
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;verify_retry_prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Fix failed: {{ error }}. Try again.&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;rollback_on_failure &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The flow:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Parse edits from source step&lt;&#x2F;li&gt;
&lt;li&gt;Apply edits&lt;&#x2F;li&gt;
&lt;li&gt;Run verification&lt;&#x2F;li&gt;
&lt;li&gt;If it fails and retries remain, show error to LLM, try again&lt;&#x2F;li&gt;
&lt;li&gt;If all retries fail, rollback&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;The retry loop is the difference. Instead of failing on first bad edit, llm-mux
shows the error and asks for a fix. Most failures are small mistakes a second
attempt catches.&lt;&#x2F;p&gt;
&lt;p&gt;Rollback uses git stash. No external tooling.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;an-example&quot;&gt;An Example&lt;&#x2F;h2&gt;
&lt;p&gt;The rust-audit workflow runs four parallel audits and writes structured docs:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;llm-mux&lt;&#x2F;span&gt;&lt;span&gt; run rust-audit
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;llm-mux&lt;&#x2F;span&gt;&lt;span&gt; run rust-audit outdir=reports&#x2F;feb-audit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Output:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;docs&#x2F;audit&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;├── README.md          # Summary table
&lt;&#x2F;span&gt;&lt;span&gt;├── 01-safety.md       # Memory safety
&lt;&#x2F;span&gt;&lt;span&gt;├── 02-performance.md  # Perf issues
&lt;&#x2F;span&gt;&lt;span&gt;├── 03-errors.md       # Error handling
&lt;&#x2F;span&gt;&lt;span&gt;└── 04-idioms.md       # Patterns
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Each audit is its own query step. Each saves to a file. The final step synthesizes
a summary. The &lt;code&gt;outdir&lt;&#x2F;code&gt; argument makes it reusable.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-llm-mux-is-not&quot;&gt;What llm-mux Is Not&lt;&#x2F;h2&gt;
&lt;p&gt;llm-mux is not a replacement for lok&#x27;s CLI commands. There&#x27;s no &lt;code&gt;llm-mux ask&lt;&#x2F;code&gt; or
&lt;code&gt;llm-mux hunt&lt;&#x2F;code&gt;. It&#x27;s purely a workflow runner.&lt;&#x2F;p&gt;
&lt;p&gt;If you want quick one-off queries, use lok. If you want structured multi-step
pipelines with proper abstractions, use llm-mux.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m keeping both. They solve different problems.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-doesn-t-work-yet&quot;&gt;What Doesn&#x27;t Work Yet&lt;&#x2F;h2&gt;
&lt;p&gt;The template system is powerful but error messages are cryptic. A typo in a Jinja
variable gives you a wall of minijinja internals.&lt;&#x2F;p&gt;
&lt;p&gt;HTTP backend streaming works but the progress output is ugly. You see chunks
arrive but it&#x27;s not as clean as the CLI backend output.&lt;&#x2F;p&gt;
&lt;p&gt;Team auto-detection is basic. It looks for files but doesn&#x27;t understand monorepos
or nested projects yet.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; install llm-mux
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;llm-mux&lt;&#x2F;span&gt;&lt;span&gt; doctor
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;llm-mux&lt;&#x2F;span&gt;&lt;span&gt; run rust-audit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Config goes in &lt;code&gt;~&#x2F;.config&#x2F;llm-mux&#x2F;config.toml&lt;&#x2F;code&gt;. Workflows go in
&lt;code&gt;.llm-mux&#x2F;workflows&#x2F;&lt;&#x2F;code&gt; or &lt;code&gt;~&#x2F;.config&#x2F;llm-mux&#x2F;workflows&#x2F;&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Source at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;llm-mux&quot;&gt;github.com&#x2F;ducks&#x2F;llm-mux&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Lok was the prototype. llm-mux is the product. The 317 people using lok helped
me figure out what the abstractions should be.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>finna: Multi-Model Debate, Spec, and Implement</title>
          <pubDate>Tue, 10 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/finna-multi-model-spec-implement/</link>
          <guid>https://jakegoldsborough.com/blog/2026/finna-multi-model-spec-implement/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/finna-multi-model-spec-implement/">&lt;p&gt;Lok&#x27;s &lt;code&gt;spec&lt;&#x2F;code&gt; command was useful but felt too coupled to the rest of the tool.
I wanted something standalone: give it an idea, get specs and code. No
configuration files, no backend setup, just a single binary that orchestrates
the models I already have installed.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s finna.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem-with-just-build-it&quot;&gt;The Problem with &quot;Just Build It&quot;&lt;&#x2F;h2&gt;
&lt;p&gt;When you ask an LLM to build something, it starts coding immediately. Maybe it
picks a good architecture, maybe it doesn&#x27;t. By the time you see the output,
you&#x27;re committed to whatever approach it chose. If the foundation is wrong,
you&#x27;re either refactoring generated code or starting over.&lt;&#x2F;p&gt;
&lt;p&gt;The fix is to separate planning from execution. But not just any planning. A
plan that multiple models have debated and agreed on, written down in files you
can review before any code gets generated.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-pipeline&quot;&gt;The Pipeline&lt;&#x2F;h2&gt;
&lt;p&gt;finna runs four stages:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;idea → debate → roadmap → spec → implement
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Debate&lt;&#x2F;strong&gt;: Claude, Codex, and Gemini independently analyze the idea&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Consensus&lt;&#x2F;strong&gt;: Claude synthesizes the proposals into a unified approach&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Roadmap&lt;&#x2F;strong&gt;: Break the consensus into ordered, dependency-aware steps&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Spec&lt;&#x2F;strong&gt;: Write detailed implementation specs for each step&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Implement&lt;&#x2F;strong&gt;: Models propose edits, Claude synthesizes, changes applied&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Each stage reads from the previous stage&#x27;s output. Everything lands in &lt;code&gt;.finna&#x2F;&lt;&#x2F;code&gt;
so you can review, edit, or re-run individual stages.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;usage&quot;&gt;Usage&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Run all stages
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Add JWT authentication to the API&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Or run stages separately
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Add JWT authentication&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# debate → roadmap
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; spec                                &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# roadmap → specs
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; implement                           &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# specs → code
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Target specific steps
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; spec&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --step&lt;&#x2F;span&gt;&lt;span&gt; auth-middleware
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; implement&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --step&lt;&#x2F;span&gt;&lt;span&gt; auth-middleware
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;a-real-example-toml-parser&quot;&gt;A Real Example: TOML Parser&lt;&#x2F;h2&gt;
&lt;p&gt;I ran finna on building a TOML parser from scratch:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;finna&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;write a toml parser in rust from scratch, no dependencies&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Three models debated the architecture. They converged on a lexer-first approach
with recursive descent parsing. The roadmap came out as 30 steps with proper
dependency ordering:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;.finna&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;├── consensus.json
&lt;&#x2F;span&gt;&lt;span&gt;├── roadmap.arf
&lt;&#x2F;span&gt;&lt;span&gt;└── specs&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    ├── 01-project-scaffold&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ├── 02-error-types&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ├── 03-token-types&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;span&gt;    ├── 16-lexer-integration&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ├── 17-parser-core&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;span&gt;    └── 30-edge-cases&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The roadmap groups work into phases: scaffold and types (1-5), lexer (6-16),
parser (17-25), public API and tests (26-30). Each step declares its
dependencies so they can&#x27;t run out of order.&lt;&#x2F;p&gt;
&lt;p&gt;Running &lt;code&gt;finna spec&lt;&#x2F;code&gt; generates detailed ARF specs for each step. Here&#x27;s the
spec for lexing basic strings:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;order &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Implement lexing for double-quoted basic strings with full escape support&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Basic strings are TOML&amp;#39;s primary string format. The lexer must process&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;escapes&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;at&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lex&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;time&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;and&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;detect&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;unterminated&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;strings&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;with&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;precise&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;error
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;locations&lt;&#x2F;span&gt;&lt;span&gt;.&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;1. Add lex_basic_string() method
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;2. Main loop: consume until closing quote or error
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;3. Implement lex_escape_sequence() for &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\t&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\n&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\r&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\\&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;\&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt;\u&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;XXXX, &lt;&#x2F;span&gt;&lt;span style=&quot;background-color:#bf616a;color:#2b303b;&quot;&gt;\U&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;XXXXXXXX
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;4. Implement lex_unicode_escape() with validation
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;5. Wire into lex_token() dispatch
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;6. Add unit tests for all escape sequences and error cases
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backup &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Defer escape processing to post-lex pass if implementation is error-prone&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[context]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;files &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;src&#x2F;lexer.rs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;src&#x2F;error.rs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dependencies &lt;&#x2F;span&gt;&lt;span&gt;= []
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The specs include test cases. The basic strings spec lists 25+ scenarios:
simple strings, escape sequences, unicode handling, error conditions. The
models know what to test because they debated it during planning.&lt;&#x2F;p&gt;
&lt;p&gt;The 30 specs totaled 2.1k lines. That&#x27;s not wasted tokens. It&#x27;s a contract you
can review before any code exists.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-arf-format&quot;&gt;The ARF Format&lt;&#x2F;h2&gt;
&lt;p&gt;Specs use TOML with a standard structure:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;order &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;one sentence description&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;context and motivation&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Step-by-step implementation plan
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backup &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;fallback approach if primary fails&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[context]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;files &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;paths&#x2F;to&#x2F;files&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dependencies &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;step names this depends on&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The format is simple on purpose. No special tooling needed to read or edit.
Any text editor works. The structure enforces that every step has a rationale,
a plan, and a fallback.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-separate-stages&quot;&gt;Why Separate Stages&lt;&#x2F;h2&gt;
&lt;p&gt;The stages are separate because you need intervention points.&lt;&#x2F;p&gt;
&lt;p&gt;After debate, review the roadmap. Does the architecture make sense? Are the
steps in the right order? Edit &lt;code&gt;.finna&#x2F;roadmap.arf&lt;&#x2F;code&gt; if not.&lt;&#x2F;p&gt;
&lt;p&gt;After spec, review the specs. Is the implementation plan correct? Are the test
cases comprehensive? Edit the spec files or re-run &lt;code&gt;finna spec --step X&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;After implement, review the changes. Did the edits apply cleanly? Is the code
what you expected? The specs told you what would happen; now verify it did.&lt;&#x2F;p&gt;
&lt;p&gt;If you run &lt;code&gt;finna &quot;idea&quot;&lt;&#x2F;code&gt; without the subcommands, it runs all stages in
sequence. That&#x27;s fine for exploration. But for real work, you probably want
the review gates.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;multi-model-consensus&quot;&gt;Multi-Model Consensus&lt;&#x2F;h2&gt;
&lt;p&gt;The debate phase isn&#x27;t just asking three models and picking one. All three
responses get synthesized:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Claude, Codex, and Gemini each propose an approach in parallel&lt;&#x2F;li&gt;
&lt;li&gt;Claude sees all three proposals and synthesizes consensus&lt;&#x2F;li&gt;
&lt;li&gt;Disagreements become explicit tradeoffs in the final plan&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;One model might over-engineer authentication. Another might skip edge cases.
The synthesis catches both failure modes. You get architecture that multiple
models have pressure-tested.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;&#x2F;h2&gt;
&lt;p&gt;finna is ~500 lines of Rust. It shells out to &lt;code&gt;claude&lt;&#x2F;code&gt;, &lt;code&gt;codex&lt;&#x2F;code&gt;, and &lt;code&gt;npx @google&#x2F;gemini-cli&lt;&#x2F;code&gt; for the actual model calls. No API keys in the binary,
no config files. If you have the CLIs installed, finna works.&lt;&#x2F;p&gt;
&lt;p&gt;The implementation phase runs models in parallel for each step, synthesizes
their edit proposals, and applies the changes. Edits are JSON with &lt;code&gt;path&lt;&#x2F;code&gt;,
&lt;code&gt;old&lt;&#x2F;code&gt;, and &lt;code&gt;new&lt;&#x2F;code&gt; fields. Simple find-and-replace, no AST manipulation.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;#[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;derive&lt;&#x2F;span&gt;&lt;span&gt;(Debug, serde::Deserialize)]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;struct &lt;&#x2F;span&gt;&lt;span&gt;Edit {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;path&lt;&#x2F;span&gt;&lt;span&gt;: String,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;old&lt;&#x2F;span&gt;&lt;span&gt;: String,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;new&lt;&#x2F;span&gt;&lt;span&gt;: String,
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If an edit can&#x27;t find the target text, it warns and continues. If the file
doesn&#x27;t exist, it creates it. The implementation is deliberately simple
because the specs already contain the complexity.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-finna-is-not&quot;&gt;What finna Is Not&lt;&#x2F;h2&gt;
&lt;p&gt;finna is not a replacement for writing code. It&#x27;s a planning tool that happens
to also generate code. The value is in the specs, not the implementation.&lt;&#x2F;p&gt;
&lt;p&gt;If the generated code is wrong, you fix the spec and re-run. If the
architecture is wrong, you fix the roadmap and re-spec. The code is a
side effect of getting the plan right.&lt;&#x2F;p&gt;
&lt;p&gt;finna is also not trying to be general-purpose. It solves one problem: turn an
idea into a structured plan with implementation. No plugins, no extensibility,
no configuration. One tool, one job.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Clone and build
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;git&lt;&#x2F;span&gt;&lt;span&gt; clone https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;finna
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;cd&lt;&#x2F;span&gt;&lt;span&gt; finna
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;nix-shell
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; build&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --release
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Run on your idea
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;.&#x2F;target&#x2F;release&#x2F;finna &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;your idea here&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Requires &lt;code&gt;claude&lt;&#x2F;code&gt;, &lt;code&gt;codex&lt;&#x2F;code&gt;, and &lt;code&gt;npx @google&#x2F;gemini-cli&lt;&#x2F;code&gt; to be installed and
authenticated. If a model fails, finna continues with the others.&lt;&#x2F;p&gt;
&lt;p&gt;The source is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;finna&quot;&gt;github.com&#x2F;ducks&#x2F;finna&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;The test project (TOML parser specs) is at
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;finna-toml-parser&quot;&gt;github.com&#x2F;ducks&#x2F;finna-toml-parser&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Building a JSON Parser with Multi-LLM Orchestration (Part 1)</title>
          <pubDate>Sat, 07 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/lok-json-parser-multi-llm/</link>
          <guid>https://jakegoldsborough.com/blog/2026/lok-json-parser-multi-llm/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/lok-json-parser-multi-llm/">&lt;p&gt;I&#x27;ve been building lok, a multi-LLM orchestration tool, and I wanted to put it
through its paces on a real project. What better than a JSON parser? It&#x27;s a
classic learning project with enough nuance to surface interesting design
decisions.&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s the premise: instead of just diving into code, what if I let multiple
LLMs debate the design first? Then synthesize their consensus into specs. Then
have them collaboratively implement it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-setup&quot;&gt;The Setup&lt;&#x2F;h2&gt;
&lt;p&gt;I started with a simple question:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;We want to write a JSON parser from scratch as a learning project.
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Debate: What language should we use? What features should it support?
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;What should the architecture look like?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Four models participated: Claude, Codex (GPT-5.2), Gemini, and Qwen 3 Coder
(running locally via Ollama).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;round-1-surprising-agreement&quot;&gt;Round 1: Surprising Agreement&lt;&#x2F;h2&gt;
&lt;p&gt;All four converged on Rust. The reasoning varied:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Claude&lt;&#x2F;strong&gt; focused on the learning angle: &quot;Forces you to think about ownership
and memory layout. You&#x27;ll learn more writing a parser in Rust than in Python&#x2F;JS
where you can be sloppy.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Codex&lt;&#x2F;strong&gt; got practical: &quot;Ownership semantics force you to think about buffer
management. &lt;code&gt;Result&amp;lt;T, E&amp;gt;&lt;&#x2F;code&gt; makes error handling explicit.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Gemini&lt;&#x2F;strong&gt; went for performance: &quot;Zero-cost abstractions mean clean code
compiles to efficient machine code.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Qwen&lt;&#x2F;strong&gt; hit safety: &quot;Enums with exhaustive matching prevent invalid parser
states.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;On architecture, unanimous: lexer + recursive descent parser. No surprises
there.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;round-2-the-interesting-bits&quot;&gt;Round 2: The Interesting Bits&lt;&#x2F;h2&gt;
&lt;p&gt;Numbers sparked actual debate. The naive approach stores JSON numbers as &lt;code&gt;f64&lt;&#x2F;code&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;Number(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;f64&lt;&#x2F;span&gt;&lt;span&gt;)  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Simple but WRONG
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Codex caught it: &quot;Treating numbers as f64 is not spec-correct. JSON allows
arbitrary precision. The safest approach is storing the original string.&quot;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;Number(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;&amp;#39;a str&lt;&#x2F;span&gt;&lt;span&gt;)  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Preserves original, validates grammar
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is why multi-model debate works. I might have defaulted to f64 and hit
precision bugs later.&lt;&#x2F;p&gt;
&lt;p&gt;Another good catch from Gemini: recursive descent needs depth limits. Without
them, an adversarial input like &lt;code&gt;[[[[[[[[...&lt;&#x2F;code&gt; blows the stack. Simple fix, easy
to forget.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-consensus&quot;&gt;The Consensus&lt;&#x2F;h2&gt;
&lt;p&gt;After three rounds, the models settled on:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Language&lt;&#x2F;strong&gt;: Rust&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Architecture&lt;&#x2F;strong&gt;: Lexer (iterator-based) + Recursive Descent Parser&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Number handling&lt;&#x2F;strong&gt;: Store as string, not f64&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Zero-copy&lt;&#x2F;strong&gt;: Use &lt;code&gt;Cow&amp;lt;&#x27;a, str&amp;gt;&lt;&#x2F;code&gt; where possible&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Safety&lt;&#x2F;strong&gt;: Configurable depth limits&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Features&lt;&#x2F;strong&gt;: RFC 8259 strict first, extensions later&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;generating-specs&quot;&gt;Generating Specs&lt;&#x2F;h2&gt;
&lt;p&gt;With design decisions locked, I fed the debate conclusions into &lt;code&gt;lok spec&lt;&#x2F;code&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spec &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build a JSON parser in Rust with these design decisions:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;- Lexer + Recursive Descent Parser
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;- Numbers stored as string, not f64
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;- Zero-copy with Cow&amp;lt;&amp;#39;a, str&amp;gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;- Depth limits for safety
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;- RFC 8259 strict compliance&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This queries multiple backends, synthesizes a consensus roadmap, then breaks
each step into subtasks. The output:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;.arf&#x2F;specs&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;  roadmap.arf
&lt;&#x2F;span&gt;&lt;span&gt;  01-core_types&#x2F;     (5 subtasks) - Span, Error, Token, Value
&lt;&#x2F;span&gt;&lt;span&gt;  02-lexer&#x2F;          (5 subtasks) - Iterator-based tokenizer
&lt;&#x2F;span&gt;&lt;span&gt;  03-parser&#x2F;         (4 subtasks) - Recursive descent
&lt;&#x2F;span&gt;&lt;span&gt;  04-number_validation&#x2F; (2 subtasks) - RFC 8259 number format
&lt;&#x2F;span&gt;&lt;span&gt;  05-error_reporting&#x2F;   (4 subtasks) - Line&#x2F;column errors
&lt;&#x2F;span&gt;&lt;span&gt;  06-test_suite&#x2F;        (3 subtasks) - JSONTestSuite compliance
&lt;&#x2F;span&gt;&lt;span&gt;  07-extension_hooks&#x2F;   (4 subtasks) - Future comments&#x2F;trailing commas
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Each subtask is an &lt;code&gt;.arf&lt;&#x2F;code&gt; file (Agent Reasoning Format) with structured fields:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;order &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Core Lexer struct implementing Iterator over tokens&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;file &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;src&#x2F;lexer&#x2F;lexer.rs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Main lexing logic that transforms input bytes into token stream&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Struct Lexer&amp;lt;&amp;#39;a&amp;gt; with input: &amp;amp;&amp;#39;a str, pos: usize. Implement
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Iterator&amp;lt;Item = Result&amp;lt;Token&amp;lt;&amp;#39;a&amp;gt;, LexError&amp;gt;&amp;gt;. Dispatch on current
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;byte: punctuation returns immediately, keywords verify literals,
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;strings handle escapes, numbers capture as slice.
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[context]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;inputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Raw JSON string&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;outputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Stream of Token results&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;These specs become the contract for implementation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-multi-model-debate-surfaces&quot;&gt;What Multi-Model Debate Surfaces&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Edge cases no single model catches.&lt;&#x2F;strong&gt; The f64 precision issue came from Codex.
The depth limit vulnerability came from Gemini. Each model has blind spots.
Claude focused on educational value, Codex on spec correctness, Gemini on
performance, Qwen on safety.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Consensus beats any single model.&lt;&#x2F;strong&gt; Not because the average is smarter, but
because different models catch different things. Three rounds of debate with
four models surfaced issues I&#x27;d have hit weeks into implementation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;What&#x27;s Next&lt;&#x2F;h2&gt;
&lt;p&gt;Part 2 will cover &lt;code&gt;lok implement&lt;&#x2F;code&gt;, which takes these specs and:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Queries multiple backends in parallel for each subtask&lt;&#x2F;li&gt;
&lt;li&gt;Synthesizes consensus code from the proposals&lt;&#x2F;li&gt;
&lt;li&gt;Writes the file and verifies it compiles&lt;&#x2F;li&gt;
&lt;li&gt;Commits each file with an atomic git commit&lt;&#x2F;li&gt;
&lt;li&gt;Records structured reasoning traces (ARF) alongside the code&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;The implementation phase is where things get interesting. Backends disagree on
details, synthesis has to resolve conflicts, and verification catches when the
generated code doesn&#x27;t actually compile.&lt;&#x2F;p&gt;
&lt;p&gt;Stay tuned.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Lok Part 5: Multi-Agent Planning with lok spec</title>
          <pubDate>Fri, 06 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/lok-spec-multi-agent-planning/</link>
          <guid>https://jakegoldsborough.com/blog/2026/lok-spec-multi-agent-planning/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/lok-spec-multi-agent-planning/">&lt;p&gt;The hardest part of building software isn&#x27;t writing code. It&#x27;s figuring out what
to build and in what order. LLMs are great at generating code, but they&#x27;re also
great at generating the wrong code because they started implementing before
thinking through the structure.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s what &lt;code&gt;lok spec&lt;&#x2F;code&gt; solves.&lt;&#x2F;p&gt;
&lt;p&gt;This post describes the shape of the system: how lok structures planning, what
guarantees the spec format provides, and why separation between planner and
executor matters. The implementation of the executor (agents actually writing
code) is not covered here. This is about constraints and contracts.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-lok-is-not&quot;&gt;What Lok is not&lt;&#x2F;h2&gt;
&lt;p&gt;Before going further:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Not a chatbot framework or conversational interface&lt;&#x2F;li&gt;
&lt;li&gt;Not a marketplace or plugin system for third-party agents&lt;&#x2F;li&gt;
&lt;li&gt;Not trying to replace developers with automation&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Lok is a planner that structures work and an executor that requires explicit
human approval at every phase boundary. The design assumes humans review specs,
trigger execution, and validate results.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem-with-just-build-it&quot;&gt;The Problem with &quot;Just Build It&quot;&lt;&#x2F;h2&gt;
&lt;p&gt;When you give an LLM a big task like &quot;build a C compiler,&quot; it starts coding
immediately. Maybe it picks the lexer first, maybe the parser. Maybe it designs
types that won&#x27;t work for later phases. By the time you realize the architecture
is wrong, you&#x27;ve burned tokens and time.&lt;&#x2F;p&gt;
&lt;p&gt;The fix is obvious in retrospect: plan before you build. But not just any plan.
A plan that multiple models have debated and converged on.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;propose-refine-pick&quot;&gt;Propose, Refine, Pick&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;code&gt;lok spec&lt;&#x2F;code&gt; uses a three-step process:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Propose&lt;&#x2F;strong&gt;: All backends generate roadmaps in parallel&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Refine&lt;&#x2F;strong&gt;: Synthesize roadmaps into a consensus plan&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Pick&lt;&#x2F;strong&gt;: Generate detailed specs from the consensus&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;This is the same pattern as debate mode, but applied to planning instead of
analysis. Each backend proposes how they&#x27;d structure the project. Then we
synthesize the best ideas and resolve contradictions. Finally, we generate
specs that capture the agreed approach.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spec &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build a C compiler in Rust. Take C source as input, produce x86-64
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;  assembly output. Include lexer, parser, semantic analysis, and code
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;  generation. Focus on correctness over optimization.&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;spec: Planning: Build a C compiler in Rust...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;spec: Step 1&#x2F;3: Getting roadmaps from 4 backends...
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ 4&#x2F;4 backends responded
&lt;&#x2F;span&gt;&lt;span&gt;spec: Step 2&#x2F;3: Synthesizing consensus roadmap...
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ Consensus reached
&lt;&#x2F;span&gt;&lt;span&gt;spec: Step 3&#x2F;3: Generating detailed specs...
&lt;&#x2F;span&gt;&lt;span&gt;spec: Step 4&#x2F;4: Breaking specs into subtasks...
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ lexer → 4 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ ast → 5 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ parser → 5 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ semantic → 5 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ ir → 5 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ codegen → 5 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ driver → 4 subtasks
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;==================================================
&lt;&#x2F;span&gt;&lt;span&gt;spec: Generated 7 specs in .arf&#x2F;specs&#x2F;:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  + roadmap.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 01-lexer&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 01-lexer&#x2F;01-token.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 01-lexer&#x2F;02-cursor.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 01-lexer&#x2F;03-scanner.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 01-lexer&#x2F;04-keywords.arf
&lt;&#x2F;span&gt;&lt;span&gt;  + 02-ast&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;  ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Four backends looked at &quot;build a C compiler&quot; and each proposed a roadmap. Claude
synthesized them into a unified plan. Then we generated specs for each step, and
broke each step into subtasks (individual files).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-output-structure&quot;&gt;The Output Structure&lt;&#x2F;h2&gt;
&lt;p&gt;Specs land in &lt;code&gt;.arf&#x2F;specs&#x2F;&lt;&#x2F;code&gt; with a nested structure:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;.arf&#x2F;specs&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;  roadmap.arf
&lt;&#x2F;span&gt;&lt;span&gt;  01-lexer&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    01-token.arf
&lt;&#x2F;span&gt;&lt;span&gt;    02-cursor.arf
&lt;&#x2F;span&gt;&lt;span&gt;    03-scanner.arf
&lt;&#x2F;span&gt;&lt;span&gt;    04-keywords.arf
&lt;&#x2F;span&gt;&lt;span&gt;  02-ast&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;    spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;    01-types.arf
&lt;&#x2F;span&gt;&lt;span&gt;    02-expr.arf
&lt;&#x2F;span&gt;&lt;span&gt;    ...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The roadmap is the high-level plan. Each numbered directory is a step. Inside
each step is a &lt;code&gt;spec.arf&lt;&#x2F;code&gt; with the overall component spec, plus subtask files
for individual pieces.&lt;&#x2F;p&gt;
&lt;p&gt;A spec file looks like this:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;order &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build the lexer to tokenize C source code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Parser needs a stream of tokens, not raw characters&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Hand-written scanner with keyword trie, handles preprocessor directives&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backup &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Fall back to regex-based tokenizer if performance is acceptable&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[context]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;inputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;C source code as string or file path&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;outputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Iterator of Token structs with location info&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dependencies &lt;&#x2F;span&gt;&lt;span&gt;= []
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;tests &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Tokenize test files, compare against expected token sequences&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;A subtask file adds a &lt;code&gt;file&lt;&#x2F;code&gt; field:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;order &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;1
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Define token types and structures&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;file &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;src&#x2F;lexer&#x2F;token.rs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;All other lexer components depend on token definitions&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Enum for token kinds, struct for token with span and value&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[context]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;inputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;None - foundational types&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;outputs &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Token enum, TokenKind enum, Span struct&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;tests &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Unit tests for token construction and display&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;planning-to-execution-flow&quot;&gt;Planning to Execution Flow&lt;&#x2F;h2&gt;
&lt;p&gt;Here is the minimal end-to-end for a boring but real task: refactoring Rust
error handling to use &lt;code&gt;thiserror&lt;&#x2F;code&gt; crate. Replace manual &lt;code&gt;impl Display&lt;&#x2F;code&gt; with
derive macro. Update all error construction sites.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spec &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Refactor error types to use thiserror crate. Replace manual Display
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;  impls with derive macro. Update all error construction sites.&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Output:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;.arf&#x2F;specs&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;  roadmap.arf
&lt;&#x2F;span&gt;&lt;span&gt;  01-add-dependency&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;  02-refactor-errors&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;span&gt;  02-refactor-errors&#x2F;01-lexer-error.arf
&lt;&#x2F;span&gt;&lt;span&gt;  02-refactor-errors&#x2F;02-parser-error.arf
&lt;&#x2F;span&gt;&lt;span&gt;  03-update-callsites&#x2F;spec.arf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Review the roadmap and specs. If the plan looks wrong, edit the &lt;code&gt;.arf&lt;&#x2F;code&gt; files or
regenerate. Once satisfied:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; implement .arf&#x2F;specs&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Agents read each spec and implement the changes directly. Each agent works on
its assigned file according to the spec. The boundary between planning and
execution is the review gate - you decide when to run &lt;code&gt;lok implement&lt;&#x2F;code&gt; after
reviewing the specs.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;&#x2F;h2&gt;
&lt;p&gt;The spec files are &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;arf&quot;&gt;ARF&lt;&#x2F;a&gt; format. That means
they&#x27;re structured, parseable, and auditable. When you review a spec, you&#x27;re
reviewing the plan before any code exists. If the approach is wrong, you catch
it here, not after 10,000 lines of generated code.&lt;&#x2F;p&gt;
&lt;p&gt;The subtask breakdown is what enables parallel execution. Once you have specs
for &lt;code&gt;01-token.arf&lt;&#x2F;code&gt;, &lt;code&gt;02-cursor.arf&lt;&#x2F;code&gt;, &lt;code&gt;03-scanner.arf&lt;&#x2F;code&gt;, and &lt;code&gt;04-keywords.arf&lt;&#x2F;code&gt;,
different agents can work on different files simultaneously. They&#x27;re not
stepping on each other because each owns their file.&lt;&#x2F;p&gt;
&lt;p&gt;The pattern is recursive. &lt;code&gt;lok spec&lt;&#x2F;code&gt; on a project gives you steps. Each step
has subtasks. If a subtask is still too big, you could spec it again. Same
process, different scale.&lt;&#x2F;p&gt;
&lt;p&gt;The spec format enforces three invariants:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Serializable plans&lt;&#x2F;strong&gt;: Every decision is written down in parseable TOML.
You can diff plans, version them, replay them.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Attributable actions&lt;&#x2F;strong&gt;: Each spec names the file it will modify or create.
No agent can touch code without a spec that declares intent.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Human intervention points&lt;&#x2F;strong&gt;: Spec generation is separate from execution.
You review the plan before any code changes happen.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;These are not optimizations. They are constraints that prevent the system from
becoming a black box.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;human-in-the-loop-by-design&quot;&gt;Human in the Loop by Design&lt;&#x2F;h2&gt;
&lt;p&gt;The separation between &lt;code&gt;lok spec&lt;&#x2F;code&gt; and execution is not a temporary limitation.
It is the core design. The system does not &quot;learn&quot; to skip human review or
&quot;graduate&quot; to autonomous operation.&lt;&#x2F;p&gt;
&lt;p&gt;Every phase boundary requires explicit human approval:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Spec generation produces files you review before execution starts&lt;&#x2F;li&gt;
&lt;li&gt;Execution runs subtasks but does not merge or deploy results&lt;&#x2F;li&gt;
&lt;li&gt;Integration is a separate manual step&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This is not because the LLMs are not capable enough. It is because software
built by delegation requires inspection and veto power at decision boundaries.
The moment you remove that, you have an agent that makes choices you cannot
audit until after the damage is done.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;single-backend-fallback&quot;&gt;Single Backend Fallback&lt;&#x2F;h2&gt;
&lt;p&gt;If you only have one backend configured, &lt;code&gt;lok spec&lt;&#x2F;code&gt; skips the multi-model
consensus and just asks that backend to plan and spec directly. You still get
the structured output, just without the debate.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spec&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --backend&lt;&#x2F;span&gt;&lt;span&gt; claude &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build a REST API&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The value of multi-backend consensus is catching blind spots. One model might
over-engineer the auth system while another keeps it simple. Synthesis finds
the middle ground. But if you&#x27;re just exploring or don&#x27;t have multiple backends
set up, single-model works fine.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;token-conservation&quot;&gt;Token Conservation&lt;&#x2F;h2&gt;
&lt;p&gt;The multi-agent pattern has a cost: API calls. Four backends generating roadmaps
is four API calls. Synthesis is another. Spec generation is another. Subtask
generation is one per step.&lt;&#x2F;p&gt;
&lt;p&gt;For a 7-step project, that&#x27;s roughly: 4 (roadmaps) + 1 (synthesize) + 1 (specs)&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;7 (subtasks) = 13 API calls. Not cheap if you&#x27;re using expensive models.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;But here&#x27;s the key: every backend&#x27;s contribution gets used. We&#x27;re not querying
four models and throwing away three responses. We&#x27;re synthesizing all four into
something better than any single response.&lt;&#x2F;p&gt;
&lt;p&gt;This is the rule I&#x27;ve been following: if you fire off multiple agents, they
must debate or synthesize. Never query N backends just to pick one.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;What&#x27;s Next&lt;&#x2F;h2&gt;
&lt;p&gt;The specs exist. The next step is execution: read the specs, assign agents to
subtasks, run them in parallel, integrate the results. That is a bigger piece of
machinery, but the foundation is here.&lt;&#x2F;p&gt;
&lt;p&gt;For now, &lt;code&gt;lok spec&lt;&#x2F;code&gt; gives you a structured plan that multiple models have
agreed on. Review it, tweak it if needed, then start building with confidence
that the architecture makes sense. The system does not get smarter by hiding
decisions from you. It gets more useful by making decisions inspectable.&lt;&#x2F;p&gt;
&lt;p&gt;The source is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;github.com&#x2F;ducks&#x2F;lok&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Previous: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-the-self-healing-loop&quot;&gt;Part 4: The Self-Healing Loop&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>ARF: Structured Reasoning for AI Agents</title>
          <pubDate>Mon, 02 Feb 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/arf-structured-reasoning-for-ai-agents/</link>
          <guid>https://jakegoldsborough.com/blog/2026/arf-structured-reasoning-for-ai-agents/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/arf-structured-reasoning-for-ai-agents/">&lt;h3 id=&quot;the-problem-with-prompts&quot;&gt;The Problem with Prompts&lt;&#x2F;h3&gt;
&lt;p&gt;The deeper I get into building with LLMs, the more I realize the &quot;chat prompt&quot;
model works but could be better.&lt;&#x2F;p&gt;
&lt;p&gt;When you give an agent an unstructured prompt, it runs with it. Sometimes
brilliantly. Sometimes it hallucinates a photographer named &quot;Chris Lawton&quot;
because it couldn&#x27;t parse a webpage and decided to make something up instead
of saying &quot;I don&#x27;t know.&quot; The lack of structure means the agent decides what
matters, what to skip, and what to invent.&lt;&#x2F;p&gt;
&lt;p&gt;This is fine for casual Q&amp;amp;A. It falls apart when you&#x27;re building tools that
need to be auditable, reviewable, or predictable.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;from-lok-to-arf&quot;&gt;From lok to ARF&lt;&#x2F;h3&gt;
&lt;p&gt;I&#x27;ve been building &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;lok&lt;&#x2F;a&gt;, an LLM orchestration
tool that runs multi-step workflows across different backends. One thing
became clear: the more structure I added, the better the results.&lt;&#x2F;p&gt;
&lt;p&gt;Workflows with explicit steps, defined inputs, and expected outputs work.
Workflows that just say &quot;figure it out&quot; produce garbage as often as gold.&lt;&#x2F;p&gt;
&lt;p&gt;This led to a question: what if we standardized how agents communicate their
reasoning? Not just &quot;here&#x27;s my answer&quot; but &quot;here&#x27;s what I&#x27;m doing, why I&#x27;m
doing it, how I plan to do it, and what I&#x27;ll do if it fails.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;The result is ARF (Agent Reasoning Format), a simple spec for structured
agent reasoning.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-format&quot;&gt;The Format&lt;&#x2F;h3&gt;
&lt;p&gt;ARF records are TOML files with required and optional fields:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;what &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Add retry logic to API client&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Transient failures causing user-visible errors&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;how &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Exponential backoff with 3 retries, circuit breaker after 5 failures&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backup &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Revert to synchronous error handling if latency increases&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;timestamp &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;2026-02-02T15:14:32Z&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;commit &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;8ae882e6&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Two fields are required:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;what&lt;&#x2F;strong&gt;: The concrete action being taken&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;why&lt;&#x2F;strong&gt;: The reasoning behind the approach&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Two fields are recommended:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;how&lt;&#x2F;strong&gt;: Implementation details&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;backup&lt;&#x2F;strong&gt;: Rollback plan if it fails&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The backup field is the interesting one. Forcing agents to declare a rollback
plan before acting means they have to think about failure modes. It&#x27;s the
difference between &quot;I&#x27;ll refactor this function&quot; and &quot;I&#x27;ll refactor this
function, and if tests fail I&#x27;ll revert to the original implementation.&quot;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;storage-orphan-branches&quot;&gt;Storage: Orphan Branches&lt;&#x2F;h3&gt;
&lt;p&gt;ARF records need to live somewhere. The options were:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Git notes (invisible, sync friction)&lt;&#x2F;li&gt;
&lt;li&gt;Nested repo (coordination overhead)&lt;&#x2F;li&gt;
&lt;li&gt;Orphan branch (separate history, same repo)&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;I ran a &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;lok debate&lt;&#x2F;a&gt; across four LLM backends
to evaluate the tradeoffs. All four converged on orphan branches.&lt;&#x2F;p&gt;
&lt;p&gt;The approach uses git worktrees to mount an orphan branch at &lt;code&gt;.arf&#x2F;&lt;&#x2F;code&gt;:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;your-repo&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;├── .arf&#x2F;              # Mounted worktree (arf branch)
&lt;&#x2F;span&gt;&lt;span&gt;│   └── records&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;│       └── 8ae882e6&#x2F;  # Records by commit SHA
&lt;&#x2F;span&gt;&lt;span&gt;│           └── claude-20260202-151432.toml
&lt;&#x2F;span&gt;&lt;span&gt;├── .git&#x2F;
&lt;&#x2F;span&gt;&lt;span&gt;└── src&#x2F;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Records are organized by commit SHA. When you record reasoning, it links to
the commit you&#x27;re working on. The &lt;code&gt;.arf&#x2F;&lt;&#x2F;code&gt; directory is gitignored from the
main branch but has its own history on the orphan branch.&lt;&#x2F;p&gt;
&lt;p&gt;This keeps reasoning history completely separate from code history. You can
push, pull, and sync reasoning records without touching your main branch.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;the-cli&quot;&gt;The CLI&lt;&#x2F;h3&gt;
&lt;p&gt;The reference implementation is a Rust CLI:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Initialize ARF tracking
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;arf&lt;&#x2F;span&gt;&lt;span&gt; init
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Record reasoning for current work
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;arf&lt;&#x2F;span&gt;&lt;span&gt; record&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --what &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Add graph command&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;           --why &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Need unified view of git history with reasoning&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# View reasoning log
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;arf&lt;&#x2F;span&gt;&lt;span&gt; log
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Combined visualization
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;arf&lt;&#x2F;span&gt;&lt;span&gt; graph
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;code&gt;arf graph&lt;&#x2F;code&gt; command shows git commits alongside their reasoning records:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Git + ARF History:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;├─● 8ae882e Add diff command with ARF reasoning context
&lt;&#x2F;span&gt;&lt;span&gt;│  └─ what: Add diff command
&lt;&#x2F;span&gt;&lt;span&gt;│      why: Combine git diff with ARF reasoning for full context review
&lt;&#x2F;span&gt;&lt;span&gt;│      how: Shows reasoning header then git show output
&lt;&#x2F;span&gt;&lt;span&gt;├─● 5604413 Add graph command for unified git+arf visualization
&lt;&#x2F;span&gt;&lt;span&gt;│  └─ what: Add graph command
&lt;&#x2F;span&gt;&lt;span&gt;│      why: User requested visualization combining git commits with reasoning
&lt;&#x2F;span&gt;&lt;span&gt;│      how: Matches commit SHAs to .arf&#x2F;records&#x2F; directories
&lt;&#x2F;span&gt;&lt;span&gt;├─● 8ec6c98 Add ARF CLI reference implementation
&lt;&#x2F;span&gt;&lt;span&gt;│  └─ what: Implement ARF CLI v0.1
&lt;&#x2F;span&gt;&lt;span&gt;│      why: Need reference implementation for spec
&lt;&#x2F;span&gt;&lt;span&gt;│      how: Rust CLI with init&#x2F;record&#x2F;log&#x2F;sync commands
&lt;&#x2F;span&gt;&lt;span&gt;└─● 3384a83 Initial ARF spec v0.1
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The &lt;code&gt;arf diff&lt;&#x2F;code&gt; command shows a single commit with reasoning context:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;═══════════════════════════════════════════════════════════════
&lt;&#x2F;span&gt;&lt;span&gt;Commit: 8ae882e Add diff command with ARF reasoning context
&lt;&#x2F;span&gt;&lt;span&gt;═══════════════════════════════════════════════════════════════
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;REASONING:
&lt;&#x2F;span&gt;&lt;span&gt;  what: Add diff command
&lt;&#x2F;span&gt;&lt;span&gt;  why:  Combine git diff with ARF reasoning for full context review
&lt;&#x2F;span&gt;&lt;span&gt;  how:  Shows reasoning header then git show output
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;───────────────────────────────────────────────────────────────
&lt;&#x2F;span&gt;&lt;span&gt;CHANGES:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt; src&#x2F;main.rs | 118 +++++++++++++++++++++++++++
&lt;&#x2F;span&gt;&lt;span&gt; 1 file changed, 118 insertions(+)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is &quot;review the reasoning, not just the diff.&quot;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;&#x2F;h3&gt;
&lt;p&gt;The shift happening in AI tooling is from unstructured to structured. Chat
interfaces are training wheels. Production systems need:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Declared intent&lt;&#x2F;strong&gt;: What are you trying to do?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Explicit reasoning&lt;&#x2F;strong&gt;: Why this approach?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Failure planning&lt;&#x2F;strong&gt;: What if it breaks?&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Audit trails&lt;&#x2F;strong&gt;: What happened and why?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;ARF is one piece of this. It&#x27;s not a replacement for git commit messages or
PR descriptions. It&#x27;s a parallel track for capturing reasoning that doesn&#x27;t
belong in code history but shouldn&#x27;t be lost.&lt;&#x2F;p&gt;
&lt;p&gt;When an agent makes a change, the diff shows what changed. The ARF record
shows why that approach was chosen over alternatives, what tradeoffs were
considered, and what the rollback plan is.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;using-it&quot;&gt;Using It&lt;&#x2F;h3&gt;
&lt;p&gt;The spec and CLI are on GitHub:
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;arf&quot;&gt;github.com&#x2F;ducks&#x2F;arf&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Install with Cargo:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;cargo&lt;&#x2F;span&gt;&lt;span&gt; install&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --git&lt;&#x2F;span&gt;&lt;span&gt; https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;arf
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The format is intentionally minimal. Four fields, two required. Easy to
generate, easy to parse, easy to extend.&lt;&#x2F;p&gt;
&lt;p&gt;If you&#x27;re building agent tooling and want structured reasoning, try it out.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>I Built a Robot to Help Me Understand People</title>
          <pubDate>Sat, 31 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/building-a-robot-to-understand-humans/</link>
          <guid>https://jakegoldsborough.com/blog/2026/building-a-robot-to-understand-humans/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/building-a-robot-to-understand-humans/">&lt;p&gt;I am good with machines and bad with people.&lt;&#x2F;p&gt;
&lt;p&gt;This is not false modesty. I can trace a request through twelve microservices and
find the one misconfigured timeout. I can read a stack trace and know which
library is lying. I can debug race conditions that only happen on Tuesdays.&lt;&#x2F;p&gt;
&lt;p&gt;But ask me to read a room? To pick up on what someone is really saying in a
meeting? To notice when a coworker is frustrated before they explicitly say so?
That is where I struggle.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;writing-is-easier&quot;&gt;Writing Is Easier&lt;&#x2F;h2&gt;
&lt;p&gt;I do better with written communication. Forum posts, Slack messages, pull
request descriptions. When people write, they leave a trail I can actually
follow. I can re-read it. I can search it. I can take my time.&lt;&#x2F;p&gt;
&lt;p&gt;In person, the signal moves too fast. By the time I have processed what someone
said, we have moved on. I miss the subtext because I am still working on the
text.&lt;&#x2F;p&gt;
&lt;p&gt;This is probably why I ended up in infrastructure. Machines do not have subtext.
A 502 error is a 502 error.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;graham-duncan-s-question&quot;&gt;Graham Duncan&#x27;s Question&lt;&#x2F;h2&gt;
&lt;p&gt;A coworker recently wrote about Graham Duncan&#x27;s framework for evaluating people.
I had never heard of it, so I did some research. Duncan is an investor
known for his approach to assessing people. His core question is:&lt;&#x2F;p&gt;
&lt;p&gt;&quot;What&#x27;s going on here, with this human?&quot;&lt;&#x2F;p&gt;
&lt;p&gt;Not &quot;are they qualified?&quot; or &quot;do they have the right experience?&quot; but something
deeper. What patterns show up in how they communicate? What do they care about?
How do they handle disagreement? What are they not saying?&lt;&#x2F;p&gt;
&lt;p&gt;Duncan&#x27;s framework breaks this down into dimensions:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Self-awareness and blind spots&lt;&#x2F;li&gt;
&lt;li&gt;Hidden motivations and fears&lt;&#x2F;li&gt;
&lt;li&gt;How they respond to stress and uncertainty&lt;&#x2F;li&gt;
&lt;li&gt;Contextual fit (right person, wrong role?)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I realized this is exactly what I struggle to do in real-time with coworkers.
But what if I could do it asynchronously, with written artifacts, with a
machine&#x27;s help?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-data-is-already-there&quot;&gt;The Data Is Already There&lt;&#x2F;h2&gt;
&lt;p&gt;At Discourse, we use our own product internally. Years of forum posts, technical
discussions, weekly updates, casual banter. A written record of how people
think, communicate, and collaborate.&lt;&#x2F;p&gt;
&lt;p&gt;This is the kind of data I can actually work with.&lt;&#x2F;p&gt;
&lt;p&gt;So I built a tool. It pulls someone&#x27;s forum activity, reads through their posts,
and generates a structured evaluation. Communication style. Areas of expertise.
How they handle disagreement. Patterns that emerge over time.&lt;&#x2F;p&gt;
&lt;p&gt;It is not a replacement for actually talking to people. But it gives me a
starting point. A cheat sheet for understanding someone before I walk into a
1:1 or try to give feedback.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-it-actually-produces&quot;&gt;What It Actually Produces&lt;&#x2F;h2&gt;
&lt;p&gt;The output is a structured report:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Executive summary (what stands out about this person?)&lt;&#x2F;li&gt;
&lt;li&gt;Core strengths with evidence from actual posts&lt;&#x2F;li&gt;
&lt;li&gt;Growth areas, framed constructively&lt;&#x2F;li&gt;
&lt;li&gt;Communication profile (tone, clarity, patterns)&lt;&#x2F;li&gt;
&lt;li&gt;Collaboration dynamics (how do they work with others?)&lt;&#x2F;li&gt;
&lt;li&gt;Representative quotes that capture their voice&lt;&#x2F;li&gt;
&lt;li&gt;Discussion prompts for 1:1s&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;That last section is the most useful for me. Specific questions I can ask based
on what someone has actually written about. Not generic &quot;how&#x27;s it going?&quot; but
&quot;you mentioned being frustrated with X last month, how&#x27;s that going?&quot;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-uncomfortable-part&quot;&gt;The Uncomfortable Part&lt;&#x2F;h2&gt;
&lt;p&gt;There is something uncomfortable about using a machine to understand people.
It feels like cheating. Or like admitting a deficiency that maybe I should just
work on directly.&lt;&#x2F;p&gt;
&lt;p&gt;But I have been &quot;working on it directly&quot; for decades and I am still bad at it.
At some point you have to accept your constraints and build around them.&lt;&#x2F;p&gt;
&lt;p&gt;I use a calendar because I cannot remember appointments. I use a todo list
because I cannot hold tasks in my head. I use version control because I cannot
trust myself to not break things.&lt;&#x2F;p&gt;
&lt;p&gt;Why not use a tool to help me understand people?&lt;&#x2F;p&gt;
&lt;h2 id=&quot;not-a-replacement&quot;&gt;Not a Replacement&lt;&#x2F;h2&gt;
&lt;p&gt;This does not replace actual human interaction. It is prep work. The same way
you might review someone&#x27;s recent commits before a code review, or skim their
last few PRs before a 1:1.&lt;&#x2F;p&gt;
&lt;p&gt;The conversations still happen. The relationship still matters. I just show up
slightly less clueless about what is going on with this human.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;try-it&quot;&gt;Try It&lt;&#x2F;h2&gt;
&lt;p&gt;The tool is open source if you want to try it:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt; plugin marketplace add ducks&#x2F;person-eval
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt; plugin install person-eval@person-eval&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --scope&lt;&#x2F;span&gt;&lt;span&gt; user
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Then in Claude Code:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;person-eval username https:&#x2F;&#x2F;your-discourse-site.com
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Or with a timeframe for yearly reviews:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;&#x2F;person-eval username https:&#x2F;&#x2F;your-discourse-site.com 2025
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It requires the discourse-mcp server to be configured, which gives Claude Code
access to Discourse data.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-irony&quot;&gt;The Irony&lt;&#x2F;h2&gt;
&lt;p&gt;The irony is not lost on me. I built a machine to help me understand humans
because I understand machines better than humans.&lt;&#x2F;p&gt;
&lt;p&gt;But maybe that is fine. We all have different strengths. Mine happen to involve
making robots do things. If I can make a robot help me be a better coworker,
that seems like a reasonable trade.&lt;&#x2F;p&gt;
&lt;p&gt;The goal is not to replace human connection with machine analysis. The goal is
to show up more prepared, more aware, more able to actually connect when the
moment comes.&lt;&#x2F;p&gt;
&lt;p&gt;I am still bad with people. But I am getting better at compensating for it.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Lok Part 4: The Self-Healing Loop</title>
          <pubDate>Wed, 28 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/lok-the-self-healing-loop/</link>
          <guid>https://jakegoldsborough.com/blog/2026/lok-the-self-healing-loop/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/lok-the-self-healing-loop/">&lt;p&gt;Last time I showed lok finding 25 bugs in itself and creating GitHub issues
automatically. Today it fixed one of those bugs, submitted a PR, and then
found a real bug in Discourse that I just pushed upstream.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;agentic-workflows&quot;&gt;Agentic Workflows&lt;&#x2F;h2&gt;
&lt;p&gt;The missing piece was letting lok actually do things, not just talk about them.
I added a few fields to the workflow TOML:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;fix&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;apply_edits &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;verify &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;cargo build&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Fix this issue. Output JSON:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;{&amp;quot;edits&amp;quot;: [{&amp;quot;file&amp;quot;: &amp;quot;src&#x2F;main.rs&amp;quot;, &amp;quot;old&amp;quot;: &amp;quot;...&amp;quot;, &amp;quot;new&amp;quot;: &amp;quot;...&amp;quot;}], &amp;quot;summary&amp;quot;: &amp;quot;...&amp;quot;}
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;commit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;shell &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;git add -A &amp;amp;&amp;amp; git commit -m &amp;#39;{{ steps.fix.summary }}&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;fix&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Three new things:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;shell&lt;&#x2F;code&gt; runs a command instead of querying an LLM&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;apply_edits&lt;&#x2F;code&gt; parses JSON from the LLM and patches files&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;verify&lt;&#x2F;code&gt; runs after edits to make sure they work&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;The &lt;code&gt;{{ steps.fix.summary }}&lt;&#x2F;code&gt; bit extracts a field from the JSON output. You
can also do &lt;code&gt;{{ arg.1 }}&lt;&#x2F;code&gt; for positional arguments, so &lt;code&gt;lok run fix-issue 42&lt;&#x2F;code&gt;
passes 42 into the workflow.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lok-fixes-itself&quot;&gt;Lok Fixes Itself&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&#x2F;issues&#x2F;25&quot;&gt;Issue #25&lt;&#x2F;a&gt; was about a redundant &lt;code&gt;Clone&lt;&#x2F;code&gt; implementation. The &lt;code&gt;Delegator&lt;&#x2F;code&gt; struct
already derives Clone, but there was a manual impl at the bottom of the file
doing the same thing.&lt;&#x2F;p&gt;
&lt;p&gt;I ran the fix workflow:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; run fix-issue 25
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It analyzed the issue, generated an edit to delete the redundant impl, applied
it, ran &lt;code&gt;cargo build&lt;&#x2F;code&gt; to verify, committed with a message based on the fix
summary, pushed the branch, and opened a PR.&lt;&#x2F;p&gt;
&lt;p&gt;The whole loop took maybe 30 seconds. I reviewed the diff, looked reasonable,
merged it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;finding-bugs-in-discourse&quot;&gt;Finding Bugs in Discourse&lt;&#x2F;h2&gt;
&lt;p&gt;Feeling confident, I pointed lok at the main Discourse codebase:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; hunt &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;discourse&#x2F;discourse
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Both Codex and Claude found issues. Most were minor (confusing patterns, style
things) but two stood out:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A chat job with a TODO saying &quot;delete after 2025-01-01&quot; that was still there
in January 2026. Pure dead code.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;A bug in the thread serializer. It had this pattern:&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;ruby&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-ruby &quot;&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span&gt;@&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;opts&lt;&#x2F;span&gt;&lt;span&gt;[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;:include_thread_original_message&lt;&#x2F;span&gt;&lt;span&gt;].presence || &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The problem is &lt;code&gt;.presence&lt;&#x2F;code&gt; on &lt;code&gt;false&lt;&#x2F;code&gt; returns &lt;code&gt;nil&lt;&#x2F;code&gt;. So if you explicitly pass
&lt;code&gt;include_thread_original_message: false&lt;&#x2F;code&gt;, it gets converted to &lt;code&gt;nil&lt;&#x2F;code&gt;, then
&lt;code&gt;|| true&lt;&#x2F;code&gt; kicks in, and your option is ignored.&lt;&#x2F;p&gt;
&lt;p&gt;One controller was passing &lt;code&gt;false&lt;&#x2F;code&gt; and getting &lt;code&gt;true&lt;&#x2F;code&gt; back. Nobody noticed
because the behavior difference is subtle, but it was definitely wrong.&lt;&#x2F;p&gt;
&lt;p&gt;I created two PRs:
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;discourse&#x2F;discourse&#x2F;pull&#x2F;37333&quot;&gt;#37333&lt;&#x2F;a&gt;
&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;discourse&#x2F;discourse&#x2F;pull&#x2F;37334&quot;&gt;#37334&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-vision&quot;&gt;The Vision&lt;&#x2F;h2&gt;
&lt;p&gt;The pieces are coming together for a fully autonomous loop:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;lok hunt --issues&lt;&#x2F;code&gt; finds bugs and creates GitHub issues&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;lok run fix-issue 42&lt;&#x2F;code&gt; analyzes, fixes, verifies, commits, opens PR&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;lok run review-pr 43&lt;&#x2F;code&gt; has multiple backends review the diff&lt;&#x2F;li&gt;
&lt;li&gt;If they agree, merge&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Humans become exception handlers. You get pinged when the LLMs disagree or
flag something they are not confident about. Otherwise the codebase quietly
improves itself.&lt;&#x2F;p&gt;
&lt;p&gt;We are not there yet. The fix workflow needs better error recovery, the review
workflow needs the debate mode integrated, and I want confidence scores on
the merge decision. But the foundation is solid.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;What&#x27;s Next&lt;&#x2F;h2&gt;
&lt;p&gt;Honestly, I&#x27;m not 100% sure. I plan to just keep using it and adding&#x2F;fixing things
that I want or need. Stay tuned to see how the project evolves.&lt;&#x2F;p&gt;
&lt;p&gt;Next stop: unknown. But the tracks are laid.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Previous: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-dogfooding-and-code-review&quot;&gt;Part 3: Dogfooding and Code Review&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Lok Part 3: Dogfooding and Code Review</title>
          <pubDate>Tue, 27 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/lok-dogfooding-and-code-review/</link>
          <guid>https://jakegoldsborough.com/blog/2026/lok-dogfooding-and-code-review/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/lok-dogfooding-and-code-review/">&lt;p&gt;Part 2 ended with two promises: parallel workflow execution and dead code cleanup.
Both happened. But the more interesting development was lok creating GitHub issues
for bugs it found in itself.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;hunt-with-issues&quot;&gt;Hunt with Issues&lt;&#x2F;h2&gt;
&lt;p&gt;The &lt;code&gt;lok hunt&lt;&#x2F;code&gt; command scans for bugs using multiple LLM backends. The new
&lt;code&gt;--issues&lt;&#x2F;code&gt; flag takes it further: parse the findings and create GitHub issues
automatically.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; hunt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --issues                    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Find bugs, create issues
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; hunt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --issues -y                 &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Skip confirmation prompt
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; hunt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --issues --issue-backend&lt;&#x2F;span&gt;&lt;span&gt; gitlab  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Force GitLab instead of GitHub
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The implementation auto-detects whether to use &lt;code&gt;gh&lt;&#x2F;code&gt; (GitHub CLI) or &lt;code&gt;glab&lt;&#x2F;code&gt;
(GitLab CLI) by checking the git remote URL:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;detect_from_remote&lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;dir&lt;&#x2F;span&gt;&lt;span&gt;: &amp;amp;Path) -&amp;gt; Option&amp;lt;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;Self&lt;&#x2F;span&gt;&lt;span&gt;&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let&lt;&#x2F;span&gt;&lt;span&gt; output = Command::new(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;git&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;)
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;args&lt;&#x2F;span&gt;&lt;span&gt;([&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;remote&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;get-url&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;origin&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;])
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;current_dir&lt;&#x2F;span&gt;&lt;span&gt;(dir)
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;output&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;ok&lt;&#x2F;span&gt;&lt;span&gt;()?;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let&lt;&#x2F;span&gt;&lt;span&gt; url = String::from_utf8_lossy(&amp;amp;output.stdout).&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;to_lowercase&lt;&#x2F;span&gt;&lt;span&gt;();
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;if&lt;&#x2F;span&gt;&lt;span&gt; url.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;contains&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;github.com&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;) {
&lt;&#x2F;span&gt;&lt;span&gt;        Some(IssueBackend::GitHub)
&lt;&#x2F;span&gt;&lt;span&gt;    } &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;else if&lt;&#x2F;span&gt;&lt;span&gt; url.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;contains&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;gitlab.com&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;) || url.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;contains&lt;&#x2F;span&gt;&lt;span&gt;(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;gitlab.&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;) {
&lt;&#x2F;span&gt;&lt;span&gt;        Some(IssueBackend::GitLab)
&lt;&#x2F;span&gt;&lt;span&gt;    } &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;else &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Fall back to checking which CLI is installed
&lt;&#x2F;span&gt;&lt;span&gt;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; ...
&lt;&#x2F;span&gt;&lt;span&gt;    }
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Self-hosted GitLab instances work too (the &lt;code&gt;gitlab.&lt;&#x2F;code&gt; check catches
&lt;code&gt;gitlab.mycompany.com&lt;&#x2F;code&gt;).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;lok-reviews-itself&quot;&gt;Lok Reviews Itself&lt;&#x2F;h2&gt;
&lt;p&gt;The real test: run &lt;code&gt;lok hunt --issues -y&lt;&#x2F;code&gt; on the lok repository itself.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;$&lt;&#x2F;span&gt;&lt;span&gt; lok hunt&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --issues -y
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Task:&lt;&#x2F;span&gt;&lt;span&gt; hunt
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;Find&lt;&#x2F;span&gt;&lt;span&gt; bugs and code issues
&lt;&#x2F;span&gt;&lt;span&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;=================================================
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;[errors]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;CLAUDE&lt;&#x2F;span&gt;&lt;span&gt; ===
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;1. &lt;&#x2F;span&gt;&lt;span&gt;**Unchecked path canonicalization** - `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;src&#x2F;main.rs:271&lt;&#x2F;span&gt;&lt;span&gt;`
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt; Uses `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;unwrap_or_else&lt;&#x2F;span&gt;&lt;span&gt;` to silently fall back on failure
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt; Backends expecting absolute paths may behave unexpectedly
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;2. &lt;&#x2F;span&gt;&lt;span&gt;**Unvalidated PR URL parsing** - `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;src&#x2F;main.rs:1320-1323&lt;&#x2F;span&gt;&lt;span&gt;`
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt; No validation that URL has enough path segments
&lt;&#x2F;span&gt;&lt;span&gt;   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;-&lt;&#x2F;span&gt;&lt;span&gt; Malformed URLs like `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;https:&#x2F;&#x2F;github.com&#x2F;foo&lt;&#x2F;span&gt;&lt;span&gt;` will panic
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;CODEX&lt;&#x2F;span&gt;&lt;span&gt; ===
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;1&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;src&#x2F;cache.rs:121&lt;&#x2F;span&gt;&lt;span&gt; — `&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;read_to_string&lt;&#x2F;span&gt;&lt;span&gt;(...)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;.ok&lt;&#x2F;span&gt;&lt;span&gt;()?` silently drops IO errors
&lt;&#x2F;span&gt;&lt;span&gt;2) src&#x2F;workflow.rs:241 — `find(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;...&lt;&#x2F;span&gt;&lt;span&gt;)&lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;.unwrap&lt;&#x2F;span&gt;&lt;span&gt;()` can panic on duplicate steps
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[perf]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=== CLAUDE ===
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;1. **O(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;n×m&lt;&#x2F;span&gt;&lt;span&gt;) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;consensus&lt;&#x2F;span&gt;&lt;span&gt; checking** - `src&#x2F;debate.rs:176-189`
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;2. &lt;&#x2F;span&gt;&lt;span&gt;**Regex compiled per interpolation call** - `src&#x2F;workflow.rs:282-294`
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;CODEX&lt;&#x2F;span&gt;&lt;span&gt; ===
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;1. &lt;&#x2F;span&gt;&lt;span&gt;`src&#x2F;workflow.rs:89` &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;—&lt;&#x2F;span&gt;&lt;span&gt; Linear `.find` &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;over&lt;&#x2F;span&gt;&lt;span&gt; steps, O(n^2) &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;with&lt;&#x2F;span&gt;&lt;span&gt; many steps
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;2. &lt;&#x2F;span&gt;&lt;span&gt;`src&#x2F;workflow.rs:279` &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;—&lt;&#x2F;span&gt;&lt;span&gt; Regex recompiled on every `interpolate` &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;call
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;[dead-code]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;=&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;== &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;CLAUDE&lt;&#x2F;span&gt;&lt;span&gt; ===
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;1. &lt;&#x2F;span&gt;&lt;span&gt;**src&#x2F;backend&#x2F;mod.rs:1-9** - Bedrock module feature-gated but never enabled
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;2. &lt;&#x2F;span&gt;&lt;span&gt;**src&#x2F;cache.rs** - `Cache::clear()` &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;method&lt;&#x2F;span&gt;&lt;span&gt; defined but never called
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Both backends found real issues. Claude and Codex agreed on several (the regex
recompilation, the O(n^2) workflow lookups) and each caught things the other
missed.&lt;&#x2F;p&gt;
&lt;p&gt;Then the issues got created:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;==================================================
&lt;&#x2F;span&gt;&lt;span&gt;issues: Creating GitHub issues in ducks&#x2F;lok
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Found 25 potential issues:
&lt;&#x2F;span&gt;&lt;span&gt;  1. src&#x2F;cache.rs:121 — silently drops IO errors
&lt;&#x2F;span&gt;&lt;span&gt;  2. src&#x2F;workflow.rs:241 — find(...).unwrap() can panic
&lt;&#x2F;span&gt;&lt;span&gt;  3. Regex compiled per interpolation call
&lt;&#x2F;span&gt;&lt;span&gt;  ...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Creating issue: src&#x2F;cache.rs:121...  ✓ https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&#x2F;issues&#x2F;1
&lt;&#x2F;span&gt;&lt;span&gt;Creating issue: src&#x2F;workflow.rs:241... ✓ https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&#x2F;issues&#x2F;2
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;Creating issue: src&#x2F;spawn.rs:381-384... ✓ https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&#x2F;issues&#x2F;25
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;✓ Created 25 issues
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;25 GitHub issues from a single command. The tool found bugs in itself and opened
tickets to track them. Each issue body includes the full finding context and
which backend reported it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;pr-review&quot;&gt;PR Review&lt;&#x2F;h2&gt;
&lt;p&gt;The &lt;code&gt;lok pr&lt;&#x2F;code&gt; command reviews GitHub pull requests:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; pr 123                              &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Current repo
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; pr owner&#x2F;repo#123                   &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Specific repo
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; pr https:&#x2F;&#x2F;github.com&#x2F;o&#x2F;r&#x2F;pull&#x2F;123  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# From URL
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It fetches PR metadata and diff via &lt;code&gt;gh&lt;&#x2F;code&gt;, constructs a review prompt, and sends
it to the configured backends. Feedback is organized by severity (critical,
important, minor, nitpick).&lt;&#x2F;p&gt;
&lt;p&gt;The value is having it as a single command instead of copy-pasting diffs into
chat windows. Run &lt;code&gt;lok pr&lt;&#x2F;code&gt; on your own PRs before requesting review. It catches
the obvious stuff so human reviewers can focus on architecture.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;explain-mode&quot;&gt;Explain Mode&lt;&#x2F;h2&gt;
&lt;p&gt;The &lt;code&gt;lok explain&lt;&#x2F;code&gt; command explains codebases:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; explain                         &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Current directory
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; explain &#x2F;path&#x2F;to&#x2F;project        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Specific project
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; explain&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --focus&lt;&#x2F;span&gt;&lt;span&gt; auth            &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Focus on specific aspect
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It gathers context automatically: README, package manifests (Cargo.toml,
package.json, etc.), and a two-level directory tree. Then asks the backend to
explain purpose, architecture, key files, and entry points.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;code&gt;--focus&lt;&#x2F;code&gt; flag is useful for large codebases. Instead of explaining
everything, ask specifically about auth, database access, or API structure.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; explain &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;&#x2F;work&#x2F;discourse&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --focus &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;background jobs&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;context-detection&quot;&gt;Context Detection&lt;&#x2F;h2&gt;
&lt;p&gt;Part 2 mentioned false positives from lok flagging N+1 queries in codebases that
use auto-eager-loading. Context detection fixes this.&lt;&#x2F;p&gt;
&lt;p&gt;Lok scans for framework and tooling markers before constructing prompts:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub struct &lt;&#x2F;span&gt;&lt;span&gt;CodebaseContext {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;detected_language&lt;&#x2F;span&gt;&lt;span&gt;: Option&amp;lt;String&amp;gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;is_rails&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;has_goldiloader&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;has_bullet&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;has_brakeman&lt;&#x2F;span&gt;&lt;span&gt;: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; ...
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;When running N+1 detection on a Rails app with Goldiloader, the prompt includes:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: This codebase uses Goldiloader for automatic eager loading. Many
apparent N+1 patterns may be handled automatically. Focus on cases where
Goldiloader wouldn&#x27;t help.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;This reduced false positives significantly. Check what lok detects with:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; context .
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;parallel-workflows&quot;&gt;Parallel Workflows&lt;&#x2F;h2&gt;
&lt;p&gt;Steps without dependencies now run in parallel:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find code patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;dead-code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find dead code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# These two run in parallel (no dependencies)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;synthesize&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;dead-code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Combine: {{ steps.patterns.output }} {{ steps.dead-code.output }}&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For workflows that hit multiple backends, this cuts total time significantly.
A three-backend scan that took 15 seconds sequentially now takes 6 seconds.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;diff-review&quot;&gt;Diff Review&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;code&gt;lok diff&lt;&#x2F;code&gt; reviews local changes before committing:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; diff                    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Staged changes
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; diff&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --unstaged         &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# All uncommitted changes
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; diff main..HEAD         &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Branch vs main
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; diff HEAD&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;~&lt;&#x2F;span&gt;&lt;span&gt;3             &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Last 3 commits
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Same idea as PR review, but catches issues before they become PR comments.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-pattern&quot;&gt;The Pattern&lt;&#x2F;h2&gt;
&lt;p&gt;A few days in, a usage pattern has emerged:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Exploratory work&lt;&#x2F;strong&gt;: Let Claude Code call &lt;code&gt;lok ask&lt;&#x2F;code&gt; with different backends
as needed. The LLM decides when to get second opinions.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Repeatable analysis&lt;&#x2F;strong&gt;: Define workflows in TOML. Run with &lt;code&gt;lok run&lt;&#x2F;code&gt;.
Parallel execution makes multi-backend scans fast.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Code review&lt;&#x2F;strong&gt;: &lt;code&gt;lok diff&lt;&#x2F;code&gt; before committing, &lt;code&gt;lok pr&lt;&#x2F;code&gt; before requesting
review. Catches obvious issues early.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bug tracking&lt;&#x2F;strong&gt;: &lt;code&gt;lok hunt --issues&lt;&#x2F;code&gt; to find bugs and create tickets in one
command.&lt;&#x2F;p&gt;
&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;Lok isn&#x27;t trying to replace your LLM session. It&#x27;s a tool your LLM session can
use. The orchestration intelligence stays in the conductor (Claude, GPT,
whatever you&#x27;re chatting with). Lok just provides the interface to multiple
specialized backends.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;What&#x27;s Next&lt;&#x2F;h2&gt;
&lt;p&gt;Those 25 issues on the lok repo need fixing. The O(n^2) workflow lookups and
regex recompilation are the most impactful. The silent error swallowing in the
cache layer should probably at least log warnings.&lt;&#x2F;p&gt;
&lt;p&gt;The PR review could be smarter about large diffs. Right now it truncates at 50k
characters. Chunking with overlap would preserve context better.&lt;&#x2F;p&gt;
&lt;p&gt;And the issue creation could get smarter about deduplication. Right now it
dedupes by title within a single run, but doesn&#x27;t check for existing open
issues with similar titles.&lt;&#x2F;p&gt;
&lt;p&gt;The source is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;github.com&#x2F;ducks&#x2F;lok&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Previous: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-workflows-and-local-llms&quot;&gt;Part 2: Workflows and Local LLMs&lt;&#x2F;a&gt; |
Next: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-the-self-healing-loop&quot;&gt;Part 4: The Self-Healing Loop&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Lok Part 2: Workflows and Local LLMs</title>
          <pubDate>Sun, 25 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/lok-workflows-and-local-llms/</link>
          <guid>https://jakegoldsborough.com/blog/2026/lok-workflows-and-local-llms/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/lok-workflows-and-local-llms/">&lt;p&gt;Since &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;introducing-lok-multi-llm-orchestration&#x2F;&quot;&gt;introducing Lok&lt;&#x2F;a&gt;, two
features emerged from actual use: local LLM support via Ollama, and a declarative
workflow engine. Both solve real problems I hit while using the tool.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ollama-local-llms-without-the-api-tax&quot;&gt;Ollama: Local LLMs Without the API Tax&lt;&#x2F;h2&gt;
&lt;p&gt;Cloud APIs are great until they&#x27;re not. Rate limits, quota exhaustion, latency
spikes, privacy concerns. Sometimes you just want to run a model locally and not
worry about any of that.&lt;&#x2F;p&gt;
&lt;p&gt;Ollama runs LLMs on your machine via a simple HTTP API. Lok now supports it as a
first-class backend:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# ~&#x2F;.config&#x2F;lok&#x2F;lok.toml
&lt;&#x2F;span&gt;&lt;span&gt;[backends.ollama]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;enabled &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;true
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;command &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;http:&#x2F;&#x2F;localhost:11434&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;llama3.2&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; ask&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --backend&lt;&#x2F;span&gt;&lt;span&gt; ollama &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Explain this function&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The implementation is straightforward. Ollama exposes a &lt;code&gt;&#x2F;api&#x2F;chat&lt;&#x2F;code&gt; endpoint that
accepts JSON. No CLI binary to shell out to, no stdout parsing. Just HTTP.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;chat&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt&lt;&#x2F;span&gt;&lt;span&gt;: &amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;str&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Result&amp;lt;String&amp;gt; {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let&lt;&#x2F;span&gt;&lt;span&gt; request = ChatRequest {
&lt;&#x2F;span&gt;&lt;span&gt;        model: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;.model.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;clone&lt;&#x2F;span&gt;&lt;span&gt;(),
&lt;&#x2F;span&gt;&lt;span&gt;        messages: vec![ChatMessage {
&lt;&#x2F;span&gt;&lt;span&gt;            role: &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;user&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;to_string&lt;&#x2F;span&gt;&lt;span&gt;(),
&lt;&#x2F;span&gt;&lt;span&gt;            content: prompt.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;to_string&lt;&#x2F;span&gt;&lt;span&gt;(),
&lt;&#x2F;span&gt;&lt;span&gt;        }],
&lt;&#x2F;span&gt;&lt;span&gt;        stream: &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;false&lt;&#x2F;span&gt;&lt;span&gt;,
&lt;&#x2F;span&gt;&lt;span&gt;    };
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let&lt;&#x2F;span&gt;&lt;span&gt; response = &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;.client
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;post&lt;&#x2F;span&gt;&lt;span&gt;(format!(&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;{}&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&#x2F;api&#x2F;chat&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;.base_url))
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;json&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;request)
&lt;&#x2F;span&gt;&lt;span&gt;        .&lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;send&lt;&#x2F;span&gt;&lt;span&gt;()
&lt;&#x2F;span&gt;&lt;span&gt;        .await?;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;&#x2F;&#x2F; Parse response...
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;When to use Ollama:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Privacy-sensitive codebases that can&#x27;t hit external APIs&lt;&#x2F;li&gt;
&lt;li&gt;Avoiding rate limits during intensive analysis sessions&lt;&#x2F;li&gt;
&lt;li&gt;Cost control (no per-token billing)&lt;&#x2F;li&gt;
&lt;li&gt;Offline development environments&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;&lt;strong&gt;Trade-offs:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Slower than cloud APIs on most hardware&lt;&#x2F;li&gt;
&lt;li&gt;Model quality depends on what you can run locally&lt;&#x2F;li&gt;
&lt;li&gt;Requires Ollama running as a daemon&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;In practice, I use Ollama for synthesis steps where I&#x27;m combining outputs from
faster cloud models. The final summarization doesn&#x27;t need to be fast, it needs
to be private and reliable.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;workflows-declarative-multi-step-pipelines&quot;&gt;Workflows: Declarative Multi-Step Pipelines&lt;&#x2F;h2&gt;
&lt;p&gt;Single-shot LLM calls are useful, but real analysis often requires multiple
passes. First a fast scan, then a deep investigation, then synthesis. Doing this
manually means copy-pasting outputs between commands.&lt;&#x2F;p&gt;
&lt;p&gt;Workflows solve this by defining multi-step pipelines in TOML:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# ~&#x2F;.config&#x2F;lok&#x2F;workflows&#x2F;security-review.toml
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;security-review&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Multi-pass security review with synthesis&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;initial-scan&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find obvious security issues: injection, auth bypass, hardcoded secrets&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;deep-audit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;initial-scan&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Review these findings and investigate deeper:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;{{ steps.initial-scan.output }}
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;synthesize&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;ollama&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;initial-scan&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;deep-audit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Combine into a prioritized report:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Initial: {{ steps.initial-scan.output }}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Deep: {{ steps.deep-audit.output }}
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Run it with:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; run security-review
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The output:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Running workflow: security-review
&lt;&#x2F;span&gt;&lt;span&gt;Multi-pass security review with synthesis
&lt;&#x2F;span&gt;&lt;span&gt;==================================================
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[step] initial-scan
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ (2.3s)
&lt;&#x2F;span&gt;&lt;span&gt;[step] deep-audit
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ (8.1s)
&lt;&#x2F;span&gt;&lt;span&gt;[step] synthesize
&lt;&#x2F;span&gt;&lt;span&gt;  ✓ (4.2s)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;==================================================
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Results:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[OK] initial-scan (2.3s)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  Found 5 potential issues:
&lt;&#x2F;span&gt;&lt;span&gt;  1. src&#x2F;api&#x2F;auth.rs:45 - SQL string interpolation
&lt;&#x2F;span&gt;&lt;span&gt;  ...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[OK] deep-audit (8.1s)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  Investigated the SQL interpolation finding...
&lt;&#x2F;span&gt;&lt;span&gt;  ...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[OK] synthesize (4.2s)
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  ## Security Review Summary
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  ### Critical (1)
&lt;&#x2F;span&gt;&lt;span&gt;  - SQL injection in auth.rs...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h3 id=&quot;variable-interpolation&quot;&gt;Variable Interpolation&lt;&#x2F;h3&gt;
&lt;p&gt;The &lt;code&gt;{{ steps.NAME.output }}&lt;&#x2F;code&gt; syntax passes previous step outputs into subsequent
prompts. The workflow engine does a simple regex replacement before sending the
prompt to the backend.&lt;&#x2F;p&gt;
&lt;p&gt;This is the key feature that makes workflows useful. Without it, you&#x27;d need
manual copy-paste between steps. With it, you can build arbitrary pipelines
where each step builds on previous results.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;dependency-resolution&quot;&gt;Dependency Resolution&lt;&#x2F;h3&gt;
&lt;p&gt;Steps declare dependencies with &lt;code&gt;depends_on&lt;&#x2F;code&gt;. The engine performs a topological
sort to determine execution order. Steps without dependencies can run in
parallel (though the current implementation runs sequentially for simplicity).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find code patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;dead-code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find dead code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;synthesize&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;patterns&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;dead-code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Combine findings:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Patterns: {{ steps.patterns.output }}
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Dead code: {{ steps.dead-code.output }}
&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&amp;quot;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The first two steps have no dependencies, so they could run concurrently. The
third step waits for both to complete before running.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;conditional-execution&quot;&gt;Conditional Execution&lt;&#x2F;h3&gt;
&lt;p&gt;Steps can include a &lt;code&gt;when&lt;&#x2F;code&gt; clause for conditional execution:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[[steps]]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;emergency-fix&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backend &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;depends_on &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;scan&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;when &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;steps.scan.output contains &amp;#39;critical&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Propose immediate fixes for critical issues...&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If the condition isn&#x27;t met, the step is skipped with a &lt;code&gt;[skip]&lt;&#x2F;code&gt; message. This
keeps workflows from doing unnecessary work.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;workflow-discovery&quot;&gt;Workflow Discovery&lt;&#x2F;h3&gt;
&lt;p&gt;Workflows are loaded from two locations:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.lok&#x2F;workflows&#x2F;&lt;&#x2F;code&gt; in the current directory (project-local)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;code&gt;~&#x2F;.config&#x2F;lok&#x2F;workflows&#x2F;&lt;&#x2F;code&gt; (global)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Project-local workflows override global ones with the same name. This lets you
define team-wide workflows globally while allowing project-specific overrides.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; workflow list
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Available workflows:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  security-review (global)
&lt;&#x2F;span&gt;&lt;span&gt;    Multi-pass security review with synthesis
&lt;&#x2F;span&gt;&lt;span&gt;    3 steps
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  code-quality (global)
&lt;&#x2F;span&gt;&lt;span&gt;    Multi-backend code quality analysis
&lt;&#x2F;span&gt;&lt;span&gt;    3 steps
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  rails-audit (local)
&lt;&#x2F;span&gt;&lt;span&gt;    Rails-specific security checks
&lt;&#x2F;span&gt;&lt;span&gt;    4 steps
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;the-plugin-system-realization&quot;&gt;The Plugin System Realization&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s the thing I didn&#x27;t plan: workflows are plugins.&lt;&#x2F;p&gt;
&lt;p&gt;When you define a workflow, you&#x27;re creating a reusable command. &lt;code&gt;lok run security-review&lt;&#x2F;code&gt; isn&#x27;t calling a built-in feature. It&#x27;s loading a TOML file and
executing it. The &quot;plugin&quot; is just configuration.&lt;&#x2F;p&gt;
&lt;p&gt;This means:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;No compilation needed to add new capabilities&lt;&#x2F;li&gt;
&lt;li&gt;Share workflows by copying TOML files&lt;&#x2F;li&gt;
&lt;li&gt;Customize existing workflows without touching Rust code&lt;&#x2F;li&gt;
&lt;li&gt;Version control your workflows alongside your code&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;A future &lt;code&gt;lok workflow install&lt;&#x2F;code&gt; could fetch workflows from URLs:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; workflow install https:&#x2F;&#x2F;example.com&#x2F;rails-audit.toml
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; run rails-audit
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The plugin system is the workflow system. No separate concepts needed.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-real-conductor-your-llm-session&quot;&gt;The Real Conductor: Your LLM Session&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s the pattern that actually works best: use your existing LLM as the
conductor, and call lok as a tool.&lt;&#x2F;p&gt;
&lt;p&gt;I run Claude Code as my daily driver. When I need multi-model analysis, I don&#x27;t
switch to &lt;code&gt;lok conduct&lt;&#x2F;code&gt;. I just ask Claude to use lok:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Me: Find performance issues in this codebase
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: [runs: lok ask --backend codex &amp;quot;Find N+1 queries and performance issues&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: I found 3 N+1 queries in the controllers. Let me get a second
&lt;&#x2F;span&gt;&lt;span&gt;        opinion on the caching strategy...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: [runs: lok ask --backend gemini &amp;quot;Review caching approach in lib&#x2F;cache.rb&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: Based on both analyses, here&amp;#39;s what I&amp;#39;d prioritize...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The LLM session becomes the orchestration layer. It sees results, reasons about
them, decides when to query other backends. No need for lok to implement its own
multi-round conversation loop.&lt;&#x2F;p&gt;
&lt;p&gt;This works because lok is just a command. It doesn&#x27;t try to be a chat interface
or maintain conversation state. It does one thing: send a prompt to backends and
return results. The intelligence stays in the LLM that&#x27;s already running.&lt;&#x2F;p&gt;
&lt;p&gt;The workflow engine complements this. For repeatable multi-step analysis, define
a workflow. For exploratory work where you need to reason about intermediate
results, let your LLM call lok directly.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;putting-it-together&quot;&gt;Putting It Together&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s my actual workflow for auditing a new codebase:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Me: Audit this codebase for security issues
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: [runs: lok run security-review]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: The workflow found 5 issues. The SQL interpolation in auth.rs
&lt;&#x2F;span&gt;&lt;span&gt;        looks serious. Let me investigate...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: [runs: lok ask --backend gemini &amp;quot;Is the SQL in auth.rs:45 exploitable?&amp;quot;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Claude: Gemini confirms it&amp;#39;s exploitable. I&amp;#39;ll draft a fix...
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Workflows handle the repeatable multi-step analysis. Claude handles the
reasoning and follow-up questions. Lok is just the interface to multiple
backends. Each layer does what it&#x27;s good at.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-next&quot;&gt;What&#x27;s Next&lt;&#x2F;h2&gt;
&lt;p&gt;The dead code that &lt;code&gt;lok hunt&lt;&#x2F;code&gt; found in its own codebase still needs cleanup.
There&#x27;s also the question of parallel step execution in workflows, which would
make multi-backend pipelines faster.&lt;&#x2F;p&gt;
&lt;p&gt;But the core loop is solid: define workflows in TOML, run them with one command,
get multi-model analysis without the manual coordination tax.&lt;&#x2F;p&gt;
&lt;p&gt;The source is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;github.com&#x2F;ducks&#x2F;lok&lt;&#x2F;a&gt;.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Previous: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;introducing-lok-multi-llm-orchestration&quot;&gt;Introducing Lok&lt;&#x2F;a&gt; |
Next: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-dogfooding-and-code-review&quot;&gt;Part 3: Dogfooding and Code Review&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>I Don&#x27;t Type Every Word You Read</title>
          <pubDate>Sun, 25 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/no-i-dont-type-every-word-you-read/</link>
          <guid>https://jakegoldsborough.com/blog/2026/no-i-dont-type-every-word-you-read/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/no-i-dont-type-every-word-you-read/">&lt;p&gt;Most modern work is already mediated by machines. Writing is just late to admit it.&lt;&#x2F;p&gt;
&lt;p&gt;Commerical pilots rarely fly planes by hand anymore. Chip designers do not solder
transistors. Photographers do not grind their own lenses. Infrastructure
engineers rarely flip physical switches in a datacenter.&lt;&#x2F;p&gt;
&lt;p&gt;In all of these fields, the work did not disappear.
It moved upstream.&lt;&#x2F;p&gt;
&lt;p&gt;Writing is undergoing the same shift.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;where-the-work-actually-is&quot;&gt;Where the Work Actually Is&lt;&#x2F;h2&gt;
&lt;p&gt;I do not type every word you read here.&lt;&#x2F;p&gt;
&lt;p&gt;That does not mean this writing is automated, synthetic, or detached from real
experience. It means the locus of effort has changed.&lt;&#x2F;p&gt;
&lt;p&gt;The work now lives in:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;deciding what is worth saying&lt;&#x2F;li&gt;
&lt;li&gt;knowing when something is wrong&lt;&#x2F;li&gt;
&lt;li&gt;recognizing when a paragraph feels hollow&lt;&#x2F;li&gt;
&lt;li&gt;choosing what to delete&lt;&#x2F;li&gt;
&lt;li&gt;setting constraints&lt;&#x2F;li&gt;
&lt;li&gt;maintaining direction&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The model generates text.
I decide what survives.&lt;&#x2F;p&gt;
&lt;p&gt;That distinction matters.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-i-actually-write-now&quot;&gt;How I Actually Write Now&lt;&#x2F;h2&gt;
&lt;p&gt;Most posts start the same way they always have: with a thought that will not
leave me alone.&lt;&#x2F;p&gt;
&lt;p&gt;Sometimes it comes from building something. Sometimes from frustration.
Sometimes from noticing the same pattern repeat across tools, systems, or
conversations.&lt;&#x2F;p&gt;
&lt;p&gt;I outline roughly. I write fragments. I ask an LLM to help me move past
blank-page friction, not to decide what I believe.&lt;&#x2F;p&gt;
&lt;p&gt;I frequently discard its output entirely.&lt;&#x2F;p&gt;
&lt;p&gt;I interrupt it mid-paragraph when it drifts. I reframe prompts when the tone
is wrong. I delete sections that feel technically correct but experientially
false.&lt;&#x2F;p&gt;
&lt;p&gt;The process is not faster because I think less.
It is faster because I spend less time fighting inertia.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;delegating-friction-not-thinking&quot;&gt;Delegating Friction, Not Thinking&lt;&#x2F;h2&gt;
&lt;p&gt;This is the part people often get backwards.&lt;&#x2F;p&gt;
&lt;p&gt;I am not delegating authorship.
I am delegating friction.&lt;&#x2F;p&gt;
&lt;p&gt;The same way a pilot delegates routine control to an autopilot in order to
focus on situational awareness, failure modes, and judgment.&lt;&#x2F;p&gt;
&lt;p&gt;Automation does not reduce responsibility.
It increases expectations.&lt;&#x2F;p&gt;
&lt;p&gt;When something goes wrong, there is still a human in the loop.
There always is.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;is-this-still-worth-reading&quot;&gt;Is This Still Worth Reading?&lt;&#x2F;h2&gt;
&lt;p&gt;That is the question people tend to circle without asking directly.&lt;&#x2F;p&gt;
&lt;p&gt;If a post reflects real experience, real constraints, and real judgment, I do
not care which tool helped shape the sentences.&lt;&#x2F;p&gt;
&lt;p&gt;Authenticity does not come from keystrokes.
It comes from context.&lt;&#x2F;p&gt;
&lt;p&gt;You can feel the difference between writing that emerged from lived systems
and writing that emerged from nowhere. Tools do not erase that distinction.&lt;&#x2F;p&gt;
&lt;p&gt;They amplify it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;writing-did-not-end-it-moved&quot;&gt;Writing Did Not End. It Moved.&lt;&#x2F;h2&gt;
&lt;p&gt;We already accept this shift everywhere else.&lt;&#x2F;p&gt;
&lt;p&gt;We do not demand that pilots prove their worth by flying without instruments.
We do not ask engineers to manage infrastructure without automation. We do
not measure photographers by how manual their camera is.&lt;&#x2F;p&gt;
&lt;p&gt;We judge outcomes, judgment, and reliability.&lt;&#x2F;p&gt;
&lt;p&gt;Writing is no different.&lt;&#x2F;p&gt;
&lt;p&gt;The work did not disappear.
It moved.&lt;&#x2F;p&gt;
&lt;p&gt;And learning where it lives now is part of the craft.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Introducing Lok: A Local Multi-LLM Orchestration Control Plane</title>
          <pubDate>Sat, 24 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/introducing-lok-multi-llm-orchestration/</link>
          <guid>https://jakegoldsborough.com/blog/2026/introducing-lok-multi-llm-orchestration/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/introducing-lok-multi-llm-orchestration/">&lt;p&gt;Large language models are getting better, but they&#x27;re also getting more
specialized. Some are fast and direct for pattern matching. Others are slower
but excel at deep, multi-step reasoning. If you work on real codebases, you&#x27;ve
probably felt the pain: no single model is &quot;best&quot; for every task, and switching
between tools manually is a constant tax.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s the problem Lok solves.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-brain-that-controls-the-arms-you-already-have&quot;&gt;The Brain That Controls the Arms You Already Have&lt;&#x2F;h2&gt;
&lt;p&gt;Lok is a local orchestration layer that coordinates multiple LLM backends
through one control plane. It wraps existing CLIs like OpenAI&#x27;s Codex and
Google&#x27;s Gemini, treating them as pluggable backends with a unified interface.&lt;&#x2F;p&gt;
&lt;p&gt;The key insight: model choice isn&#x27;t a preference anymore. It&#x27;s part of the
engineering workflow. When your toolchain includes multiple LLMs, you need
orchestration.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; hunt .          &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Bug hunt with smart backend selection
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; audit .         &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Security audit
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; team &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;analyze&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Coordinated multi-model analysis
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;async?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Let the models argue
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spawn &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;task&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Parallel agents on subtasks
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;                            ┌─────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;                            │    USER     │
&lt;&#x2F;span&gt;&lt;span&gt;                            │   (task)    │
&lt;&#x2F;span&gt;&lt;span&gt;                            └──────┬──────┘
&lt;&#x2F;span&gt;&lt;span&gt;                                   │
&lt;&#x2F;span&gt;&lt;span&gt;                                   ▼
&lt;&#x2F;span&gt;&lt;span&gt;            ┌──────────────────────────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;            │           CONDUCTOR (BRAIN)              │
&lt;&#x2F;span&gt;&lt;span&gt;            │                                          │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Analyze task complexity               │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Break into parallel subtasks          │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Assign backends via delegator         │
&lt;&#x2F;span&gt;&lt;span&gt;            └──────────────────┬───────────────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;                               │
&lt;&#x2F;span&gt;&lt;span&gt;      ┌────────────────────────┼────────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;      │                        │                        │
&lt;&#x2F;span&gt;&lt;span&gt;      ▼                        ▼                        ▼
&lt;&#x2F;span&gt;&lt;span&gt;┌───────────┐            ┌───────────┐            ┌───────────┐
&lt;&#x2F;span&gt;&lt;span&gt;│  AGENT 1  │            │  AGENT 2  │            │  AGENT 3  │
&lt;&#x2F;span&gt;&lt;span&gt;│ &amp;quot;frontend&amp;quot;│            │ &amp;quot;backend&amp;quot; │            │ &amp;quot;database&amp;quot;│
&lt;&#x2F;span&gt;&lt;span&gt;│  [CODEX]  │            │ [GEMINI]  │            │  [CODEX]  │
&lt;&#x2F;span&gt;&lt;span&gt;└─────┬─────┘            └─────┬─────┘            └─────┬─────┘
&lt;&#x2F;span&gt;&lt;span&gt;      │                        │                        │
&lt;&#x2F;span&gt;&lt;span&gt;      │     ══ PARALLEL EXECUTION ══                    │
&lt;&#x2F;span&gt;&lt;span&gt;      │                        │                        │
&lt;&#x2F;span&gt;&lt;span&gt;      └────────────────────────┼────────────────────────┘
&lt;&#x2F;span&gt;&lt;span&gt;                               │
&lt;&#x2F;span&gt;&lt;span&gt;                               ▼
&lt;&#x2F;span&gt;&lt;span&gt;            ┌──────────────────────────────────────────┐
&lt;&#x2F;span&gt;&lt;span&gt;            │         SUMMARIZATION PHASE              │
&lt;&#x2F;span&gt;&lt;span&gt;            │                                          │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Collect all agent outputs             │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Report success&#x2F;failure per agent      │
&lt;&#x2F;span&gt;&lt;span&gt;            │  • Aggregate into final summary          │
&lt;&#x2F;span&gt;&lt;span&gt;            └──────────────────────────────────────────┘
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;mode-comparison&quot;&gt;Mode Comparison&lt;&#x2F;h2&gt;
&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Mode&lt;&#x2F;th&gt;&lt;th&gt;Backends Used&lt;&#x2F;th&gt;&lt;th&gt;Execution&lt;&#x2F;th&gt;&lt;th&gt;Use Case&lt;&#x2F;th&gt;&lt;&#x2F;tr&gt;&lt;&#x2F;thead&gt;&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;smart&lt;&#x2F;td&gt;&lt;td&gt;1 (best fit)&lt;&#x2F;td&gt;&lt;td&gt;Single call&lt;&#x2F;td&gt;&lt;td&gt;Fast, targeted tasks&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;team&lt;&#x2F;td&gt;&lt;td&gt;1-3&lt;&#x2F;td&gt;&lt;td&gt;Sequential&lt;&#x2F;td&gt;&lt;td&gt;Analysis + optional peer review&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;debate&lt;&#x2F;td&gt;&lt;td&gt;2+&lt;&#x2F;td&gt;&lt;td&gt;3 rounds&lt;&#x2F;td&gt;&lt;td&gt;High-stakes decisions&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;tr&gt;&lt;td&gt;spawn&lt;&#x2F;td&gt;&lt;td&gt;2-4&lt;&#x2F;td&gt;&lt;td&gt;Parallel&lt;&#x2F;td&gt;&lt;td&gt;Complex tasks with subtasks&lt;&#x2F;td&gt;&lt;&#x2F;tr&gt;
&lt;&#x2F;tbody&gt;&lt;&#x2F;table&gt;
&lt;h2 id=&quot;smart-delegation-the-right-tool-for-the-job&quot;&gt;Smart Delegation: The Right Tool for the Job&lt;&#x2F;h2&gt;
&lt;p&gt;Not every task requires the most expensive, reasoning-heavy model. Conversely,
complex security audits shouldn&#x27;t be handled by a model optimized for speed.&lt;&#x2F;p&gt;
&lt;p&gt;Lok&#x27;s delegator (&lt;code&gt;src&#x2F;delegation.rs&lt;&#x2F;code&gt;) routes tasks based on keyword matching and
task classification:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;N+1 queries, code smells, dead code&lt;&#x2F;strong&gt;: fast, pattern-matching models (Codex, Claude Haiku)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Security audits, architecture reviews&lt;&#x2F;strong&gt;: thorough, investigative models (Gemini, o1)&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;General questions&lt;&#x2F;strong&gt;: whatever&#x27;s available (first responsive backend)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The routing logic is straightforward: task descriptions are tokenized and matched
against known patterns. If the task contains &quot;security&quot;, &quot;audit&quot;, &quot;vulnerability&quot;,
it routes to investigative models. If it contains &quot;find&quot;, &quot;search&quot;, &quot;pattern&quot;, it
routes to fast models. No ML involved - just conditional routing based on task
characteristics.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; smart &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find N+1 queries&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;           &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Routes to Codex
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; smart &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Security audit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;              &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Routes to Gemini
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; suggest &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find SQL injection&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;        &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Shows routing decision without running
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;When routing fails&lt;&#x2F;strong&gt;: If the chosen backend is unavailable, Lok falls back to
the next-best available backend. If all backends fail, you get a clear error
message listing what&#x27;s offline.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;debate-mode-built-in-skepticism&quot;&gt;Debate Mode: Built-In Skepticism&lt;&#x2F;h2&gt;
&lt;p&gt;Single-model answers are often too confident. Debate mode turns that into a
feature by making backends disagree on purpose.&lt;&#x2F;p&gt;
&lt;p&gt;In &lt;code&gt;lok debate&lt;&#x2F;code&gt;, each backend responds in multiple rounds. They see each other&#x27;s
answers and can challenge them. Round 1 is initial positions. Round 2 is
responses to each other&#x27;s positions. Round 3 is final synthesis by a judge
model that weighs all perspectives.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;What&amp;#39;s the best way to handle auth?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;How synthesis works&lt;&#x2F;strong&gt;: The judge model receives all responses with their
round numbers and prompts: &quot;Given these competing perspectives, identify points
of agreement, highlight unresolved disagreements, and synthesize a final
recommendation that acknowledges tradeoffs.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;This catches two failure modes:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;False confidence&lt;&#x2F;strong&gt;: A single model confidently recommending an antipattern&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Blind spots&lt;&#x2F;strong&gt;: One model missing a constraint that another catches&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The cost is 3x the API calls and 2-4x the latency. Use it for decisions where
being wrong is expensive.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;team-mode-coordinated-analysis&quot;&gt;Team Mode: Coordinated Analysis&lt;&#x2F;h2&gt;
&lt;p&gt;Team mode combines smart delegation with optional debate. It orchestrates the
backends like a small group:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Choose the best available backend for the task&lt;&#x2F;li&gt;
&lt;li&gt;If debate is enabled, ask others to review or challenge&lt;&#x2F;li&gt;
&lt;li&gt;Synthesize a final result&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; team &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Analyze this codebase for issues&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; team&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --debate &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Should we use async here?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This gives you both the speed of a model that&#x27;s good at the task and the rigor
of peer review. In practice, it feels like having a lead engineer and two
reviewers that don&#x27;t get tired.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;spawn-mode-parallel-agent-execution&quot;&gt;Spawn Mode: Parallel Agent Execution&lt;&#x2F;h2&gt;
&lt;p&gt;Spawn takes the coordination further. Instead of routing a single task to the
best backend, it breaks a complex task into parallel subtasks and runs multiple
agents simultaneously.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spawn &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build a todo app with frontend and backend&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The flow:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Plan&lt;&#x2F;strong&gt;: An LLM breaks the task into 2-4 independent subtasks&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Delegate&lt;&#x2F;strong&gt;: Each subtask gets assigned to the best available backend&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Execute&lt;&#x2F;strong&gt;: All agents run in parallel with shared context&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Summarize&lt;&#x2F;strong&gt;: Results are collected and aggregated&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;You can also specify agents manually:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spawn &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build an app&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;  --agent &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;api:Build REST endpoints&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;  --agent &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;ui:Build React components&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; \
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;  --agent &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;db:Design the schema&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is the conductor pattern in CLI form. A brain that plans, delegates to
specialized workers, and synthesizes results. The same pattern that makes
human teams effective, applied to LLM orchestration.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-naming-story&quot;&gt;The Naming Story&lt;&#x2F;h2&gt;
&lt;p&gt;&quot;Lok&quot; has two meanings, both relevant.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Locomotive&lt;&#x2F;strong&gt; (Swedish&#x2F;German: lokomotiv). Lok has a &lt;code&gt;conduct&lt;&#x2F;code&gt; command, and the
metaphor is intentional: a conductor sends trained models down the tracks. The
pun on &quot;trained&quot; models is deliberate.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Sanskrit&#x2F;Hindi लोक&lt;&#x2F;strong&gt; (&quot;world&quot; or &quot;people&quot;), as in Lok Sabha, the People&#x27;s
Assembly. Lok&#x27;s philosophy is a collection of agents working together, not a
single monolithic mind.&lt;&#x2F;p&gt;
&lt;p&gt;The name captures both the engineering (orchestration, routing, coordination)
and the philosophy (collective intelligence, multiple perspectives).&lt;&#x2F;p&gt;
&lt;h2 id=&quot;configuration-encode-your-team-s-knowledge&quot;&gt;Configuration: Encode Your Team&#x27;s Knowledge&lt;&#x2F;h2&gt;
&lt;p&gt;Lok works out of the box, but gets more powerful with &lt;code&gt;lok.toml&lt;&#x2F;code&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span&gt;[tasks.hunt]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find bugs and code issues&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backends &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;codex&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompts &lt;&#x2F;span&gt;&lt;span&gt;= [
&lt;&#x2F;span&gt;&lt;span&gt;  { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;n+1&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Search for N+1 query issues...&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; },
&lt;&#x2F;span&gt;&lt;span&gt;  { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;dead-code&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find unused code...&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; },
&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;[tasks.audit]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;description &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Security audit&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;backends &lt;&#x2F;span&gt;&lt;span&gt;= [&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;gemini&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompts &lt;&#x2F;span&gt;&lt;span&gt;= [
&lt;&#x2F;span&gt;&lt;span&gt;  { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;injection&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find SQL injection...&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; },
&lt;&#x2F;span&gt;&lt;span&gt;  { &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;name &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;auth&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;prompt &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find auth bypass...&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot; },
&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This isn&#x27;t just configuration. It&#x27;s a way to encode your team&#x27;s knowledge about
which model to trust for what. Tasks become repeatable workflows, not one-off
experiments.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;&#x2F;h2&gt;
&lt;p&gt;We&#x27;re moving away from the era of &quot;Prompt Engineering&quot; and into the era of Flow
Engineering. The quality of an AI output is no longer determined solely by how
clever your prompt is, but by the architecture of the workflow that processes
it.&lt;&#x2F;p&gt;
&lt;p&gt;By formalizing these flows into a CLI tool, Lok brings determinism and
reliability to AI interactions:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Higher signal, lower noise&lt;&#x2F;strong&gt;: Smart delegation keeps the right model on the
right task&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Built-in skepticism&lt;&#x2F;strong&gt;: Debate and team modes catch errors and broaden
coverage&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Parallel execution&lt;&#x2F;strong&gt;: Spawn mode runs multiple agents simultaneously,
turning sequential workflows into concurrent ones&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Repeatable workflows&lt;&#x2F;strong&gt;: Tasks like &lt;code&gt;lok hunt&lt;&#x2F;code&gt; become part of your
engineering rhythm&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Local control plane&lt;&#x2F;strong&gt;: No hidden SaaS layer, no opaque routing. You can see
and customize how it chooses backends&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;h2 id=&quot;before-and-after-a-real-example&quot;&gt;Before and After: A Real Example&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;strong&gt;Without Lok:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Manual workflow for finding Rails performance issues
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;$&lt;&#x2F;span&gt;&lt;span&gt; claude &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find N+1 queries in app&#x2F;controllers&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Review output, switch tools
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;$&lt;&#x2F;span&gt;&lt;span&gt; gemini &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Are there better caching strategies?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Manually synthesize both answers
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Total time: 5-10 minutes of context switching
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;With Lok:&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Single command, automatic backend selection and synthesis
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;$&lt;&#x2F;span&gt;&lt;span&gt; lok team&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --debate &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Analyze Rails app for performance issues&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Codex finds N+1 queries (fast, pattern-matching)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Gemini suggests caching strategies (thorough, investigative)
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Judge model synthesizes into prioritized action items
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Total time: 2 minutes, no context switching
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The value isn&#x27;t just speed - it&#x27;s that you get both the exhaustive pattern
matching and the strategic recommendations in one pass, with built-in
skepticism from debate mode catching false positives.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting Started&lt;&#x2F;h2&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Check what backends you have
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; doctor
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Ask all backends
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; ask &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find performance issues&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Let them debate
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; debate &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Best approach for caching?&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Smart routing
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; smart &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Find N+1 queries&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Parallel agents
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;lok&lt;&#x2F;span&gt;&lt;span&gt; spawn &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;Build a REST API with tests&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Lok doesn&#x27;t replace your LLMs. It coordinates them. That means you keep the
tools you already trust and add orchestration on top.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Performance characteristics&lt;&#x2F;strong&gt;: Smart routing adds ~50-100ms overhead for task
classification. Debate mode runs 3 rounds sequentially, so expect 3x the
single-model latency. Spawn mode runs agents in parallel, so wall-clock time is
determined by the slowest agent, not the sum of all agents.&lt;&#x2F;p&gt;
&lt;p&gt;The source is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;lok&quot;&gt;github.com&#x2F;ducks&#x2F;lok&lt;&#x2F;a&gt;. It&#x27;s
Rust, it&#x27;s fast, and it&#x27;s the brain that makes your AI arms work together.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;p&gt;Next: &lt;a href=&quot;&#x2F;blog&#x2F;2026&#x2F;lok-workflows-and-local-llms&quot;&gt;Part 2: Workflows and Local LLMs&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>The Unholy Trinity: Nix Shells, SSH Config, and Claude Code</title>
          <pubDate>Wed, 21 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/nix-shells-ssh-claude-code/</link>
          <guid>https://jakegoldsborough.com/blog/2026/nix-shells-ssh-claude-code/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/nix-shells-ssh-claude-code/">&lt;p&gt;I wrote about &lt;a href=&quot;&#x2F;blog&#x2F;2025&#x2F;how-i-am-using-claude-code&#x2F;&quot;&gt;using Claude Code for daily development&lt;&#x2F;a&gt;
a few months ago. That post was about workflow and mindset. This one is about
infrastructure.&lt;&#x2F;p&gt;
&lt;p&gt;Turns out, the real multiplier isn&#x27;t how you prompt the AI. It&#x27;s what you let
it touch.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-problem-with-ai-coding-assistants&quot;&gt;The Problem With AI Coding Assistants&lt;&#x2F;h2&gt;
&lt;p&gt;Most AI coding tools work in a sandbox. They can read your code, suggest
changes, maybe run a linter. But the moment you need to actually test
something, build something, deploy something? You&#x27;re back to copy-pasting
commands.&lt;&#x2F;p&gt;
&lt;p&gt;&quot;Here&#x27;s how you&#x27;d run the tests&quot; is not the same as running the tests.&lt;&#x2F;p&gt;
&lt;p&gt;Claude Code is different because it has shell access. It can run commands,
read output, iterate. But that only matters if the environment is set up for
it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;nix-shells-run-anything-anytime&quot;&gt;Nix Shells: Run Anything, Anytime&lt;&#x2F;h2&gt;
&lt;p&gt;Every project I work on has a &lt;code&gt;shell.nix&lt;&#x2F;code&gt;. When Claude needs to run something,
the command is:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;nix-shell --run &lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;bundle exec rspec&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;That&#x27;s it. No &quot;first install Rust nightly, then set up ALSA, then configure
pkg-config paths.&quot; The shell.nix declares everything. Claude doesn&#x27;t need to
know how to set up a Rust audio environment. It just needs to know &lt;code&gt;nix-shell&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;Here&#x27;s what my &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;shelltrax&quot;&gt;shelltrax&lt;&#x2F;a&gt; shell looks like:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;nix&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-nix &quot;&gt;&lt;code class=&quot;language-nix&quot; data-lang=&quot;nix&quot;&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;{ &lt;&#x2F;span&gt;&lt;span&gt;pkgs ? &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&amp;lt;nixpkgs&amp;gt; &lt;&#x2F;span&gt;&lt;span&gt;{} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;}&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;let
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;rust-overlay &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span&gt;(&lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;builtins&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;fetchTarball
&lt;&#x2F;span&gt;&lt;span&gt;    &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;https:&#x2F;&#x2F;github.com&#x2F;oxalica&#x2F;rust-overlay&#x2F;archive&#x2F;master.tar.gz&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;);
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;pkgs&amp;#39; &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&amp;lt;nixpkgs&amp;gt; &lt;&#x2F;span&gt;&lt;span&gt;{ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;overlays &lt;&#x2F;span&gt;&lt;span&gt;= [ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;rust-overlay &lt;&#x2F;span&gt;&lt;span&gt;]; };
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;rust &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkgs&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;rust-bin&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;nightly&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;latest&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;default&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;in
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkgs&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;mkShell &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;buildInputs &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;with &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkgs&amp;#39;&lt;&#x2F;span&gt;&lt;span&gt;; [
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;rust rust-analyzer
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkg-config alsa-lib openssl gcc
&lt;&#x2F;span&gt;&lt;span&gt;  ];
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Claude can run tests, build releases, check for warnings. All without me
explaining how to install Rust nightly or configure audio libraries.&lt;&#x2F;p&gt;
&lt;p&gt;The pattern works everywhere. Rust project? &lt;code&gt;nix-shell --run &quot;cargo test&quot;&lt;&#x2F;code&gt;.
Ruby project? &lt;code&gt;nix-shell --run &quot;bundle exec rspec&quot;&lt;&#x2F;code&gt;. Node? Same deal. The AI
doesn&#x27;t need to understand package managers. It just needs one command that
always works.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;ssh-config-the-revelation&quot;&gt;SSH Config: The Revelation&lt;&#x2F;h2&gt;
&lt;p&gt;I&#x27;ve had SSH config set up for years. &lt;code&gt;Host pond&lt;&#x2F;code&gt; instead of typing IPs,
key-based auth, the usual. Standard stuff for anyone who manages servers.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Host pond
&lt;&#x2F;span&gt;&lt;span&gt;    HostName 199.68.196.244
&lt;&#x2F;span&gt;&lt;span&gt;    User ducks
&lt;&#x2F;span&gt;&lt;span&gt;    IdentityFile ~&#x2F;.ssh&#x2F;pond_ed25519
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What I hadn&#x27;t considered: Claude can use it too.&lt;&#x2F;p&gt;
&lt;p&gt;I was debugging why my analytics service was down. Normally I&#x27;d open another
terminal tab, SSH in, check logs, come back and describe what I found. The
usual dance.&lt;&#x2F;p&gt;
&lt;p&gt;Instead, on a whim, I just asked Claude to check the logs. And it did.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ssh&lt;&#x2F;span&gt;&lt;span&gt; pond &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;journalctl -u goatcounter -n 50&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It found the error, suggested the fix, and I approved the command to restart
the service. I never left the conversation.&lt;&#x2F;p&gt;
&lt;p&gt;That was the moment it clicked. My SSH config wasn&#x27;t just for me anymore. Any
host I can reach, Claude can reach. Any command I can run remotely, Claude can
run remotely.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-combination&quot;&gt;The Combination&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s where it gets interesting. These two things compound.&lt;&#x2F;p&gt;
&lt;p&gt;Locally, nix-shell means Claude can build, test, and run anything in any of my
projects. Remotely, SSH config means Claude can check, restart, and deploy
anything on my servers.&lt;&#x2F;p&gt;
&lt;p&gt;The AI goes from &quot;helpful for writing code&quot; to &quot;helpful for everything.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;Example from this week: I was debugging why a webhook wasn&#x27;t firing. Claude:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;Read the local webhook handler code&lt;&#x2F;li&gt;
&lt;li&gt;SSH&#x27;d to the server to check the logs&lt;&#x2F;li&gt;
&lt;li&gt;Found the error (SSL cert issue on callback URL)&lt;&#x2F;li&gt;
&lt;li&gt;Suggested the fix&lt;&#x2F;li&gt;
&lt;li&gt;I approved, it deployed&lt;&#x2F;li&gt;
&lt;li&gt;SSH&#x27;d back to verify the fix worked&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;That&#x27;s five context switches I didn&#x27;t have to make. Five terminal tabs I
didn&#x27;t have to open. And I stayed focused on understanding the problem instead
of typing commands.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-this-enables&quot;&gt;What This Enables&lt;&#x2F;h2&gt;
&lt;p&gt;With proper setup, Claude becomes useful for:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Local development&lt;&#x2F;strong&gt; - Run tests, check linting, build assets. Not &quot;here&#x27;s
how to run tests&quot; but actually running them and reading the output.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Server management&lt;&#x2F;strong&gt; - Check service status, read logs, restart processes.
Actual ops work, not just suggesting commands.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Debugging across boundaries&lt;&#x2F;strong&gt; - Read local code, check remote logs,
correlate the two. The AI can see both sides of the problem.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Deployments&lt;&#x2F;strong&gt; - On my NixOS server, &lt;code&gt;nixos-rebuild switch&lt;&#x2F;code&gt; is the entire
deploy process. Claude can run it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-trust-question&quot;&gt;The Trust Question&lt;&#x2F;h2&gt;
&lt;p&gt;&quot;But do you really want AI SSH&#x27;d into your production server?&quot;&lt;&#x2F;p&gt;
&lt;p&gt;Fair question. My answer: it&#x27;s my personal VPS running hobby projects. The
worst case is I rebuild it from my NixOS config. If this were production
infrastructure at work, I&#x27;d be more careful.&lt;&#x2F;p&gt;
&lt;p&gt;But for personal stuff? The productivity gain is massive. And honestly,
Claude is less likely to &lt;code&gt;rm -rf &#x2F;&lt;&#x2F;code&gt; than I am after a long day.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;setting-it-up&quot;&gt;Setting It Up&lt;&#x2F;h2&gt;
&lt;p&gt;If you want to try this:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;1. Create shell.nix files for your projects&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Even a minimal one helps:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;nix&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-nix &quot;&gt;&lt;code class=&quot;language-nix&quot; data-lang=&quot;nix&quot;&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;{ &lt;&#x2F;span&gt;&lt;span&gt;pkgs ? &lt;&#x2F;span&gt;&lt;span style=&quot;color:#96b5b4;&quot;&gt;import &lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;&amp;lt;nixpkgs&amp;gt; &lt;&#x2F;span&gt;&lt;span&gt;{} &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;}&lt;&#x2F;span&gt;&lt;span&gt;:
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkgs&lt;&#x2F;span&gt;&lt;span&gt;.&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;mkShell &lt;&#x2F;span&gt;&lt;span&gt;{
&lt;&#x2F;span&gt;&lt;span&gt;  &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;buildInputs &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;with &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;pkgs&lt;&#x2F;span&gt;&lt;span&gt;; [ &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ruby nodejs yarn &lt;&#x2F;span&gt;&lt;span&gt;];
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;2. Set up SSH config with key auth&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;Host myserver
&lt;&#x2F;span&gt;&lt;span&gt;    HostName your.ip.here
&lt;&#x2F;span&gt;&lt;span&gt;    User youruser
&lt;&#x2F;span&gt;&lt;span&gt;    IdentityFile ~&#x2F;.ssh&#x2F;your_key
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;&lt;strong&gt;3. Tell Claude about it&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;In your CLAUDE.md or context file:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&quot;Use &lt;code&gt;nix-shell --run&lt;&#x2F;code&gt; for commands in projects with shell.nix&quot;&lt;&#x2F;li&gt;
&lt;li&gt;&quot;SSH host &lt;code&gt;myserver&lt;&#x2F;code&gt; is available for server operations&quot;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;That&#x27;s it. Now your AI assistant has actual hands instead of just a mouth.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-multiplier-effect&quot;&gt;The Multiplier Effect&lt;&#x2F;h2&gt;
&lt;p&gt;Good tools multiply your output. AI is a good tool. But AI with proper
environment access? That&#x27;s a different category.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m not faster because the AI writes better code. I&#x27;m faster because the AI
can actually verify what it writes. It can run tests, check logs, and iterate
without me being the middleman.&lt;&#x2F;p&gt;
&lt;p&gt;The unholy trinity: Nix makes everything reproducible. SSH makes everything
reachable. Claude ties it together.&lt;&#x2F;p&gt;
&lt;p&gt;Set up your environment right, and AI coding assistants stop being a novelty.
They become infrastructure.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Letting AI Pick the Project</title>
          <pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2026/letting-ai-pick-the-project/</link>
          <guid>https://jakegoldsborough.com/blog/2026/letting-ai-pick-the-project/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2026/letting-ai-pick-the-project/">&lt;p&gt;With the rise of AI and LLMs, a common theme has been &quot;don&#x27;t let the machine do
the thinking&quot;. The argument is we simply become expensive copy and pasters. And
while I mostly agree, I was curious.&lt;&#x2F;p&gt;
&lt;p&gt;Well, I tried an experiment today. Instead of coming to Claude Code with a
specific task, I asked: &quot;Based on everything you know, what would you build?
Create a repo, use whatever language you want, document it along the way.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;No constraints. No requirements. Just: build something.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-it-chose&quot;&gt;What It Chose&lt;&#x2F;h2&gt;
&lt;p&gt;Claude chose to build &lt;code&gt;why&lt;&#x2F;code&gt;, a CLI tool for code archaeology. The pitch:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;I spend so much of my time helping people understand codebases, and the
hardest question is always &quot;why was this decision made?&quot; The answer is
scattered across git blame, old PRs, commit messages, issue trackers, maybe
a Slack thread somewhere that&#x27;s now lost.&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;The tool points at a file or line range and synthesizes a narrative: who
introduced this code, when, what commits modified it, what issues and PRs are
referenced, what type of changes they were (bug fix, feature, security patch).&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;bash&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-bash &quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;why&lt;&#x2F;span&gt;&lt;span&gt; app&#x2F;models&#x2F;user.rb&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt; --range&lt;&#x2F;span&gt;&lt;span&gt; 100-150
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;The Story
&lt;&#x2F;span&gt;&lt;span&gt;=========
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;This code was first introduced by Jeff Atwood on 2020-05-22.
&lt;&#x2F;span&gt;&lt;span&gt;The initial commit said: &amp;quot;Revert &amp;#39;Merge branch master&amp;#39;&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Since then, it has been modified 5 time(s):
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  * FIX: do not send rejection emails to auto-deleted users (#12160)
&lt;&#x2F;span&gt;&lt;span&gt;    by Arpit Jalan
&lt;&#x2F;span&gt;&lt;span&gt;    Type: Bug fix
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;  * SECURITY: Limit name field length of TOTP authenticators
&lt;&#x2F;span&gt;&lt;span&gt;    by OsamaSayegh
&lt;&#x2F;span&gt;&lt;span&gt;    Type: Security
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;h2 id=&quot;the-process&quot;&gt;The Process&lt;&#x2F;h2&gt;
&lt;p&gt;What struck me was how Claude approached it. It started by reasoning about
what problems it encounters repeatedly. Not what would be cool to build, but
what it genuinely wished existed.&lt;&#x2F;p&gt;
&lt;p&gt;Then it moved fast. Within minutes: Rust project scaffolded, git blame
parsing working, commit categorization logic, GitHub API integration. It
tested on its own source code, then on Discourse (a large real-world
codebase I work on).&lt;&#x2F;p&gt;
&lt;p&gt;When I suggested adding Discourse as a context source (we use it for work
discussions), it designed a pluggable trait system:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;rust&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-rust &quot;&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;&lt;span&gt;#[&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;async_trait&lt;&#x2F;span&gt;&lt;span&gt;]
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;pub trait &lt;&#x2F;span&gt;&lt;span&gt;ContextSource: Send + Sync {
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;name&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; &amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;str&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;detect_references&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;text&lt;&#x2F;span&gt;&lt;span&gt;: &amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;str&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Vec&amp;lt;Reference&amp;gt;;
&lt;&#x2F;span&gt;&lt;span&gt;    async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;fetch_reference&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;reference&lt;&#x2F;span&gt;&lt;span&gt;: &amp;amp;Reference) -&amp;gt; Result&amp;lt;Option&amp;lt;ContextItem&amp;gt;&amp;gt;;
&lt;&#x2F;span&gt;&lt;span&gt;    async &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;search&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;, &lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;query&lt;&#x2F;span&gt;&lt;span&gt;: &amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;str&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; Result&amp;lt;Vec&amp;lt;ContextItem&amp;gt;&amp;gt;;
&lt;&#x2F;span&gt;&lt;span&gt;    &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;fn &lt;&#x2F;span&gt;&lt;span style=&quot;color:#8fa1b3;&quot;&gt;is_available&lt;&#x2F;span&gt;&lt;span&gt;(&amp;amp;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;self&lt;&#x2F;span&gt;&lt;span&gt;) -&amp;gt; &lt;&#x2F;span&gt;&lt;span style=&quot;color:#b48ead;&quot;&gt;bool&lt;&#x2F;span&gt;&lt;span&gt;;
&lt;&#x2F;span&gt;&lt;span&gt;}
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;GitHub and Discourse implementations, easy to add more. The architecture
emerged naturally from the feature request.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-tangents&quot;&gt;The Tangents&lt;&#x2F;h2&gt;
&lt;p&gt;We went down a few rabbit holes. I mentioned that real context often lives in
Slack threads that never got linked to the code. Claude immediately saw the
harder problem: semantic search across communication history, not just
following explicit links.&lt;&#x2F;p&gt;
&lt;p&gt;It outlined what that would require: embeddings, RAG pipelines, LLM synthesis.
Then it asked the right question: &quot;Worth building? Or is this scope creep from
a useful simple tool into a research project?&quot;&lt;&#x2F;p&gt;
&lt;p&gt;We also briefly explored turning it into an MCP server so Claude could call it
during conversations. Another good idea, but another scope expansion.&lt;&#x2F;p&gt;
&lt;p&gt;I kept pulling back to &quot;what&#x27;s actually useful now&quot; and Claude adjusted. No
ego about its ideas. Just: &quot;Good call. Let me clean up and commit.&quot;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-i-learned&quot;&gt;What I Learned&lt;&#x2F;h2&gt;
&lt;p&gt;A few observations from this experiment:&lt;&#x2F;p&gt;
&lt;p&gt;First, the AI had genuine preferences. It didn&#x27;t pick something random or
impressive-sounding. It picked a tool that would help it do its job better.
There&#x27;s something interesting about that.&lt;&#x2F;p&gt;
&lt;p&gt;Second, the iteration loop was fast. Feature idea to working code in minutes.
Not because the code was simple, but because there was no translation layer.
Claude understood what it wanted and knew how to build it.&lt;&#x2F;p&gt;
&lt;p&gt;Third, scope management mattered. Left unchecked, we could have spent hours
on semantic search and MCP servers. The human role was less about technical
direction and more about &quot;is this the thing we&#x27;re building right now?&quot;&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-tool&quot;&gt;The Tool&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;code&gt;why&lt;&#x2F;code&gt; is at &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;why&quot;&gt;github.com&#x2F;ducks&#x2F;why&lt;&#x2F;a&gt;. Rust, MIT
licensed, about 900 lines. It actually works.&lt;&#x2F;p&gt;
&lt;p&gt;Whether I&#x27;ll use it daily, I don&#x27;t know. But it exists because I asked an AI
what it would build if it could build anything, and it had an answer.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Building LLM-TUI: Never Lose Context Again</title>
          <pubDate>Tue, 16 Dec 2025 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2025/building-llm-tui-terminal-ai-chat/</link>
          <guid>https://jakegoldsborough.com/blog/2025/building-llm-tui-terminal-ai-chat/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2025/building-llm-tui-terminal-ai-chat/">&lt;p&gt;I am loving CLI agentic LLM apps except for one thing... and that&#x27;s losing context.&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;re working on a feature. You&#x27;ve shown the AI five files. You&#x27;ve explained
your architecture. You&#x27;re making progress. Then Claude crashes. Or you switch
to a different project.&lt;&#x2F;p&gt;
&lt;p&gt;When you come back tomorrow, you start over. Re-explain everything. Re-share
the files. Re-establish context.&lt;&#x2F;p&gt;
&lt;p&gt;I was taking daily notes but I got tired of that. So I built llm-tui.&lt;&#x2F;p&gt;
&lt;p&gt;It&#x27;s a terminal interface for AI chat, but that&#x27;s not the main feature. The
main feature is it remembers. File context persists across sessions. Tool
results get cached. You can close it, come back a week later, and pick up
exactly where you left off.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-it-does&quot;&gt;What It Does&lt;&#x2F;h2&gt;
&lt;p&gt;You launch it, pick a model, and chat. But the devil&#x27;s in the details.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Multi-Provider Support&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Switch between Ollama (local models on your
machine), Claude API (Anthropic&#x27;s hosted models), and AWS Bedrock (Claude via
AWS). One interface, multiple backends.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Tool System&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;When using Claude or Bedrock, the AI can Read files, Write
files, Edit existing code, search with Glob and Grep, and run Bash commands.
All sandboxed to your home directory. Every tool execution requires
confirmation (y&#x2F;n&#x2F;q).&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;File Context Persistence&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Files read during a session get cached. When you
reopen that session later, those files are already loaded. The AI remembers
what it was looking at.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Session Management&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Create named sessions, organize them by project, rename
and delete them. SQLite storage means everything persists and loads instantly.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Vim Keybindings&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Modal editing. Normal mode for navigation, insert mode for
typing, command mode for session management. j&#x2F;k to scroll, i to insert, Esc to
escape. Feels natural.&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;Token Tracking&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;Real-time display of token usage (Tokens: 1250&#x2F;200000).
When conversations get long, automatic context compaction kicks in at 75%
capacity. Old messages get summarized, recent ones stay intact.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;why-i-built-it&quot;&gt;Why I Built It&lt;&#x2F;h2&gt;
&lt;p&gt;Context loss kills productivity. You&#x27;re building a feature, the AI understands
your codebase, and then you lose it all. Browser tabs close. Sessions expire.
You switch projects and forget to save the conversation.&lt;&#x2F;p&gt;
&lt;p&gt;Starting over means minutes of setup every time. Copy file contents. Explain
your architecture again. Re-establish what the AI already knew.&lt;&#x2F;p&gt;
&lt;p&gt;I needed persistence. Sessions that survive restarts. File context that doesn&#x27;t
disappear. A tool that picks up where you left off without re-explaining
everything.&lt;&#x2F;p&gt;
&lt;p&gt;And I wanted control over which model handles the task. Local models for quick
iteration. Claude when I need reasoning. Bedrock for AWS work. One interface,
no lost context when switching.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-tool-system&quot;&gt;The Tool System&lt;&#x2F;h2&gt;
&lt;p&gt;Context persistence only works if the AI can actually interact with your files.
Browser-based chat requires copying code back and forth. Every file you want
the AI to see means another copy-paste. Every change it suggests means manually
applying edits.&lt;&#x2F;p&gt;
&lt;p&gt;The tool system fixes this. When using Claude or Bedrock, the AI can Read
files, Write files, Edit code, search with Glob and Grep, and run Bash
commands. All sandboxed to your home directory with explicit confirmation.&lt;&#x2F;p&gt;
&lt;p&gt;When the AI wants to read a file, it calls the Read tool. You see: &lt;code&gt;Read &#x2F;home&#x2F;user&#x2F;project&#x2F;foo.rs? (y&#x2F;n&#x2F;q)&lt;&#x2F;code&gt;. Same for writes and edits. You approve or
reject each action.&lt;&#x2F;p&gt;
&lt;p&gt;The key part: tool results get cached per session. If the AI reads
&lt;code&gt;config.toml&lt;&#x2F;code&gt;, that result stays in the session history. Next time you open
that session, it already knows what was in that file. No re-reading. No
re-explaining. The context persists.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-future-is-weird&quot;&gt;The Future Is Weird&lt;&#x2F;h2&gt;
&lt;p&gt;As you can probably tell, I love and prefer open source software. Unfortunately,
Claude does not fall into that category so I could not look at it for inspiration.
So, I tried a wild idea. I simply asked Claude how it&#x27;s tools worked and what the API
response looked like. And you know what, it worked! I had Claude help me basically
rebuild it&#x27;s tools by internal reflection. The future is a trip, man.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;session-management&quot;&gt;Session Management&lt;&#x2F;h2&gt;
&lt;p&gt;This is where context persistence actually lives. Each session is a separate
context with its own history, files, and conversation state. Work on multiple
projects without mixing contexts. Switch between them without losing anything.&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;:new my-feature                # New session with custom name
&lt;&#x2F;span&gt;&lt;span&gt;:project discourse-yaks        # Set current project
&lt;&#x2F;span&gt;&lt;span&gt;:rename better-name            # Rename current session
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Sessions are stored in SQLite at &lt;code&gt;~&#x2F;.local&#x2F;share&#x2F;llm-tui&#x2F;sessions.db&lt;&#x2F;code&gt;. Close
the app, come back tomorrow, and every session is exactly as you left it. The
AI still has all the files loaded. The conversation picks up mid-thought.&lt;&#x2F;p&gt;
&lt;p&gt;You can even load context from other sessions with &lt;code&gt;:load session-name&lt;&#x2F;code&gt;. Pull
in file context from a different project without manually re-sharing
everything.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;provider-management&quot;&gt;Provider Management&lt;&#x2F;h2&gt;
&lt;p&gt;Switch providers with a command:&lt;&#x2F;p&gt;
&lt;pre style=&quot;background-color:#2b303b;color:#c0c5ce;&quot;&gt;&lt;code&gt;&lt;span&gt;:provider ollama    # Local models
&lt;&#x2F;span&gt;&lt;span&gt;:provider claude    # Claude API (requires ANTHROPIC_API_KEY)
&lt;&#x2F;span&gt;&lt;span&gt;:provider bedrock   # AWS Bedrock (requires AWS credentials)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The models screen (press &lt;code&gt;3&lt;&#x2F;code&gt;) shows all available models across all providers.
Installed Ollama models marked with &lt;code&gt;[installed]&lt;&#x2F;code&gt;. Current active model marked
with &lt;code&gt;[current]&lt;&#x2F;code&gt;.&lt;&#x2F;p&gt;
&lt;p&gt;You can download Ollama models directly from the TUI. Navigate to a
non-installed model, hit Enter, and it pulls from the Ollama library. One
keypress.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;automatic-context-compaction&quot;&gt;Automatic Context Compaction&lt;&#x2F;h2&gt;
&lt;p&gt;Long conversations hit context window limits. Most chat interfaces handle this
by truncating old messages. You lose the early context that established your
architecture decisions and project structure.&lt;&#x2F;p&gt;
&lt;p&gt;llm-tui summarizes old messages instead of dropping them. At 75% capacity, it
sends old messages to the LLM for summarization. The summary replaces the
original messages, keeping under 500 tokens. Recent messages (default: 10)
always stay uncompacted.&lt;&#x2F;p&gt;
&lt;p&gt;You keep the context. The AI still knows what happened at the start of the
conversation. You just use fewer tokens to maintain it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-stack&quot;&gt;The Stack&lt;&#x2F;h2&gt;
&lt;p&gt;Written in Rust. The UI is built with ratatui (terminal UI library). SQLite for
storage via rusqlite and crossterm for terminal handling.&lt;&#x2F;p&gt;
&lt;p&gt;Three API clients: reqwest for Ollama&#x27;s HTTP API, anthropic-sdk-rust for
Claude, and AWS SDK for Bedrock.&lt;&#x2F;p&gt;
&lt;p&gt;Tool execution uses ripgrep (grep crate) for fast content search, glob for
pattern matching, and walkdir for file traversal.&lt;&#x2F;p&gt;
&lt;p&gt;Built my own vim-navigator-rs library for the modal keybindings. Normal, insert,
and command modes with proper vim-style navigation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;&#x2F;h2&gt;
&lt;p&gt;Config file at &lt;code&gt;~&#x2F;.config&#x2F;llm-tui&#x2F;config.toml&lt;&#x2F;code&gt;:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;toml&quot; style=&quot;background-color:#2b303b;color:#c0c5ce;&quot; class=&quot;language-toml &quot;&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;autosave_mode &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;onsend&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;              &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# disabled&#x2F;onsend&#x2F;timer
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ollama_model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;llama2&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;ollama_context_window &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;4096
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;claude_model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;claude-3-5-sonnet-20241022&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;claude_context_window &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;200000
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;bedrock_model &lt;&#x2F;span&gt;&lt;span&gt;= &amp;quot;&lt;&#x2F;span&gt;&lt;span style=&quot;color:#a3be8c;&quot;&gt;us.anthropic.claude-sonnet-4-20250514-v1:0&lt;&#x2F;span&gt;&lt;span&gt;&amp;quot;
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;bedrock_context_window &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;200000
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;autocompact_threshold &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;0.75          &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Compact at 75% capacity
&lt;&#x2F;span&gt;&lt;span style=&quot;color:#bf616a;&quot;&gt;autocompact_keep_recent &lt;&#x2F;span&gt;&lt;span&gt;= &lt;&#x2F;span&gt;&lt;span style=&quot;color:#d08770;&quot;&gt;10          &lt;&#x2F;span&gt;&lt;span style=&quot;color:#65737e;&quot;&gt;# Keep last 10 messages uncompacted
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Autosave modes: disabled (manual &lt;code&gt;:w&lt;&#x2F;code&gt; only), onsend (save immediately when
sending messages), or timer (save every N seconds).&lt;&#x2F;p&gt;
&lt;p&gt;Auto-start Ollama if not running (configurable). Set default provider. Pick
your context window sizes.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;roadmap&quot;&gt;Roadmap&lt;&#x2F;h2&gt;
&lt;p&gt;Still building. Next up:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI API integration&lt;&#x2F;li&gt;
&lt;li&gt;Setup wizard for API keys&lt;&#x2F;li&gt;
&lt;li&gt;Daily notes integration (load from my claude-notes directory)&lt;&#x2F;li&gt;
&lt;li&gt;Search functionality across sessions&lt;&#x2F;li&gt;
&lt;li&gt;Session export&lt;&#x2F;li&gt;
&lt;li&gt;Code block syntax highlighting&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;&#x2F;h2&gt;
&lt;p&gt;Browser-based chat interfaces are fine for casual use. But when you&#x27;re deep in
development work, context loss becomes the bottleneck. Re-explaining
architecture. Re-sharing files. Starting conversations from scratch.&lt;&#x2F;p&gt;
&lt;p&gt;llm-tui fixes that. Sessions persist. File context survives restarts. You pick
up exactly where you left off. The AI remembers what it knew yesterday.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>Like a Pig in Shit: Why I Love AI &quot;Slop&quot;</title>
          <pubDate>Sat, 08 Nov 2025 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2025/like-a-pig-in-shit-ai-slop/</link>
          <guid>https://jakegoldsborough.com/blog/2025/like-a-pig-in-shit-ai-slop/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2025/like-a-pig-in-shit-ai-slop/">&lt;p&gt;I&#x27;ve shipped more projects in the last three months than I did in the previous
year. Are they all perfect? No. Are they all polished production-grade code?
Hell no. Do I care? Not even a little bit.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m having the time of my life building whatever idea pops into my head, and AI
is the reason I can actually finish things instead of just thinking about them.&lt;&#x2F;p&gt;
&lt;p&gt;And look, shipping isn&#x27;t everything. Sometimes the best code never sees the
light of day. Sometimes you build something just to learn, or just because it
sounds fun. But there&#x27;s something deeply satisfying about making things that
actually work - even if they&#x27;re just for you.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-i-ve-been-building&quot;&gt;What I&#x27;ve Been Building&lt;&#x2F;h2&gt;
&lt;p&gt;In the last few months alone:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;vimdeck.nvim&quot;&gt;vimdeck.nvim&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: Markdown presentations in Neovim using Treesitter&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;mdpreview.nvim&quot;&gt;mdpreview.nvim&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: Live markdown preview in a split window&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;discourse-yaks&quot;&gt;discourse-yaks&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: Virtual currency system for forum posts&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;discourse-transit-tracker&quot;&gt;discourse-transit-tracker&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: Turn forums into live departure boards&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;discourse-invite-stats&quot;&gt;discourse-invite-stats&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: Invite reporting and analytics plugin&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;shelltrax&quot;&gt;shelltrax&lt;&#x2F;a&gt;&lt;&#x2F;strong&gt;: TUI music player in Rust (my daily driver now)&lt;&#x2F;li&gt;
&lt;li&gt;Plus a handful of smaller tools and fixes&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Some of these are polished. Some are &quot;good enough for me.&quot; All of them work.
All of them solve real problems I had. And I built most of them in a day or
two.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-slop-criticism&quot;&gt;The &quot;Slop&quot; Criticism&lt;&#x2F;h2&gt;
&lt;p&gt;There&#x27;s this narrative that AI-generated code is &quot;slop.&quot; Low quality, generic,
copy-pasted garbage that&#x27;s polluting the internet. And sure, that exists. That
existed before AI when people would blindly copy from Stack Overflow. But
the criticism misses something important:&lt;&#x2F;p&gt;
&lt;p&gt;When you&#x27;re building for yourself, &quot;slop&quot; doesn&#x27;t matter.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m not pushing half-baked code to production systems. I&#x27;m not claiming my
afternoon projects are enterprise-ready. I&#x27;m building tools that solve my
problems, learning by doing, and having fun.&lt;&#x2F;p&gt;
&lt;p&gt;If the markdown preview plugin has rough edges, who cares? It works for me. If
the presentation tool doesn&#x27;t handle every edge case, so what? It renders my
slides.&lt;&#x2F;p&gt;
&lt;p&gt;The &quot;slop&quot; criticism only matters when you&#x27;re shipping garbage and calling it
gold. When you&#x27;re building for yourself? Ship it, iterate, move on.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-s-actually-happening&quot;&gt;What&#x27;s Actually Happening&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s what working with AI looks like for me:&lt;&#x2F;p&gt;
&lt;p&gt;I have an idea. &quot;I want to do presentations in Neovim.&quot; Instead of spending a
week researching markdown parsers and figlet integration and buffer management,
I describe what I want and start building.&lt;&#x2F;p&gt;
&lt;p&gt;The AI suggests approaches. Some work. Some don&#x27;t. We iterate. I learn what
Treesitter can do. I understand how Neovim&#x27;s highlight system works. I see
patterns I wouldn&#x27;t have thought of.&lt;&#x2F;p&gt;
&lt;p&gt;A few hours later, I have a working plugin.&lt;&#x2F;p&gt;
&lt;p&gt;Is it perfect? No. Did I learn a ton? Yes. Can I actually use it? Absolutely.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-joy-of-building&quot;&gt;The Joy of Building&lt;&#x2F;h2&gt;
&lt;p&gt;What the critics miss is how much fun this is.&lt;&#x2F;p&gt;
&lt;p&gt;I used to have a backlog of ideas that never got built. &quot;Someday I&#x27;ll make
that.&quot; &quot;That would be cool but it&#x27;s too much work.&quot; &quot;I don&#x27;t have time to learn
X framework.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;Now? I just build it.&lt;&#x2F;p&gt;
&lt;p&gt;Want to visualize invite relationships as an ASCII tree? Build it. Want live
transit departures in a forum? Build it. Want to fix a bug in a YAML parser?
Build it and submit the fix upstream.&lt;&#x2F;p&gt;
&lt;p&gt;The barrier between &quot;I wish this existed&quot; and &quot;I built this&quot; has collapsed. And
that&#x27;s incredible.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;but-is-it-actually-good-code&quot;&gt;But Is It Actually Good Code?&lt;&#x2F;h2&gt;
&lt;p&gt;Sometimes yes, sometimes no. And that&#x27;s fine.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;kddnewton&#x2F;psych-pure&#x2F;pull&#x2F;30&quot;&gt;Ruby psych-pure bug fix&lt;&#x2F;a&gt; I
submitted? That&#x27;s good code. Full test coverage, proper edge case handling,
clean implementation. It&#x27;s going into a production library.&lt;&#x2F;p&gt;
&lt;p&gt;The &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;ducks&#x2F;discourse-transit-tracker&quot;&gt;transit tracker&lt;&#x2F;a&gt;? It
works, handles 500k+ MTA stop times, and has solid patterns for data
downloading and parsing. Could the UI be more polished? Sure. But it does what
I need and I learned a ton building it.&lt;&#x2F;p&gt;
&lt;p&gt;The key is knowing the difference. When it matters, I put in the work. When
it&#x27;s just for me, I ship it and move on.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-real-productivity-hack&quot;&gt;The Real Productivity Hack&lt;&#x2F;h2&gt;
&lt;p&gt;Working with AI isn&#x27;t about replacing thinking. It&#x27;s about spending your brain
cycles on the interesting problems instead of the boring setup work.&lt;&#x2F;p&gt;
&lt;p&gt;I don&#x27;t want to spend three hours setting up test infrastructure. I want to
spend three hours solving the actual problem. AI handles the grunt work. I
handle the decisions.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;you-can-vibe-and-still-be-productive&quot;&gt;You Can Vibe and Still Be Productive&lt;&#x2F;h2&gt;
&lt;p&gt;Here&#x27;s the thing: you can have fun, move fast, and still produce quality work.
It&#x27;s not either&#x2F;or.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m &quot;vibing out&quot; projects. Building whatever sounds interesting. Shipping fast.
And yet:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;The code works&lt;&#x2F;li&gt;
&lt;li&gt;The tests pass&lt;&#x2F;li&gt;
&lt;li&gt;The bugs get fixed&lt;&#x2F;li&gt;
&lt;li&gt;The upstream contributions get merged&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;You can be a pig in shit and still do good work. The slop is the medium, not
the output.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-gatekeeping-problem&quot;&gt;The Gatekeeping Problem&lt;&#x2F;h2&gt;
&lt;p&gt;A lot of the &quot;AI slop&quot; criticism is just gatekeeping in disguise.&lt;&#x2F;p&gt;
&lt;p&gt;&quot;Real programmers don&#x27;t use AI.&quot; &quot;You&#x27;re not actually learning.&quot; &quot;This is
ruining software quality.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;Meanwhile, I&#x27;m shipping. Learning by building. Contributing to open source.
Having fun.&lt;&#x2F;p&gt;
&lt;p&gt;The gatekeepers can argue about the &quot;right way&quot; to write code. I&#x27;m too busy
building things.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-actually-matters&quot;&gt;What Actually Matters&lt;&#x2F;h2&gt;
&lt;p&gt;At the end of the day, here&#x27;s what matters:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Does it work?&lt;&#x2F;li&gt;
&lt;li&gt;Did you learn something?&lt;&#x2F;li&gt;
&lt;li&gt;Are you having fun?&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;If the answer to those three questions is yes, then it doesn&#x27;t matter if
someone on Twitter thinks your code is &quot;slop.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;You&#x27;re building. They&#x27;re complaining. You win.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;like-a-pig-in-shit&quot;&gt;Like a Pig in Shit&lt;&#x2F;h2&gt;
&lt;p&gt;So yeah, I&#x27;m rolling around in the AI slop. Building projects at a pace I never
could before. Shipping tools that solve real problems. Learning by doing
instead of just reading about it. Old me would think I was full of shit if I
tried explaining this.&lt;&#x2F;p&gt;
&lt;p&gt;Call it slop if you want. I&#x27;m too busy having the time of my life to care.&lt;&#x2F;p&gt;
&lt;p&gt;The pig pen is the place for me.&lt;&#x2F;p&gt;
</description>
      </item>
      <item>
          <title>How I&#x27;m Using Claude Code for Daily Development Work</title>
          <pubDate>Fri, 24 Oct 2025 00:00:00 +0000</pubDate>
          <author>Unknown</author>
          <link>https://jakegoldsborough.com/blog/2025/how-i-am-using-claude-code/</link>
          <guid>https://jakegoldsborough.com/blog/2025/how-i-am-using-claude-code/</guid>
          <description xml:base="https://jakegoldsborough.com/blog/2025/how-i-am-using-claude-code/">&lt;p&gt;I&#x27;ve been using Claude Code for a few months now as my primary development assistant. Not as a replacement for thinking, but as a way to move faster on the boring stuff while keeping the interesting problems for myself.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;what-it-s-actually-good-at&quot;&gt;What It&#x27;s Actually Good At&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;the-grunt-work&quot;&gt;The Grunt Work&lt;&#x2F;h3&gt;
&lt;p&gt;Testing infrastructure is where Claude shines. Today, I needed to test SMTP error logging improvements. Instead of manually setting up &lt;a href=&quot;https:&#x2F;&#x2F;github.com&#x2F;Supermathie&#x2F;mail-relay-simulator&quot;&gt;mail-relay-simulator&lt;&#x2F;a&gt;, configuring different failure scenarios, and writing test cases, I described what I needed and got a complete Ruby script that:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Manages docker-compose lifecycle&lt;&#x2F;li&gt;
&lt;li&gt;Switches between 4 test scenarios (auth failures, wrong credentials, etc.)&lt;&#x2F;li&gt;
&lt;li&gt;Writes proper config files with correct syntax&lt;&#x2F;li&gt;
&lt;li&gt;Handles cleanup&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;The script works. It&#x27;s maintainable. It saved me 2-3 hours of tedious setup work.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;research-and-discovery&quot;&gt;Research and Discovery&lt;&#x2F;h3&gt;
&lt;p&gt;&quot;Find all the places in this codebase where we do X&quot; - this is tedious grep work that Claude excels at. It can search, cross-reference, and explain patterns without me needing to open 20 files.&lt;&#x2F;p&gt;
&lt;p&gt;Example: When investigating AWS SDK credential chain bugs, I had Claude trace through the entire credential provider chain, find where it was failing, and document the root cause. That kind of code archaeology is perfect for AI assistance.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;documentation&quot;&gt;Documentation&lt;&#x2F;h3&gt;
&lt;p&gt;Writing test results documentation, commit messages, technical proposals - Claude can take my rough notes and produce clean markdown that I&#x27;d never bother writing myself. The writeup exists because the AI made it low-effort, not because I suddenly got better at documentation.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;where-it-could-improve&quot;&gt;Where It Could Improve&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;understanding-intent&quot;&gt;Understanding Intent&lt;&#x2F;h3&gt;
&lt;p&gt;If I&#x27;m not specific about what I want, Claude will give me something that technically works but misses the point. Example: I asked for markdown rendering in Neovim. Got three different failed attempts at split-window rendering before I just said &quot;fuck it, just hard-wrap at 80 characters.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;The AI doesn&#x27;t know when to stop. It will keep trying increasingly complex solutions when the answer is &quot;do less.&quot;&lt;&#x2F;p&gt;
&lt;h3 id=&quot;production-debugging&quot;&gt;Production Debugging&lt;&#x2F;h3&gt;
&lt;p&gt;When real production issues happen, Claude&#x27;s knowledge cutoff and lack of access to live systems means it&#x27;s guessing. I can describe symptoms and it&#x27;ll suggest things to check, but it&#x27;s not replacing actual debugging experience.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;knowing-what-it-doesn-t-know&quot;&gt;Knowing What It Doesn&#x27;t Know&lt;&#x2F;h3&gt;
&lt;p&gt;The worst thing Claude does is hallucinate with confidence. It&#x27;ll make up photographer names for Unsplash images when WebFetch fails to parse the page. It&#x27;ll suggest APIs that don&#x27;t exist. It&#x27;ll confidently explain behavior that&#x27;s completely wrong.&lt;&#x2F;p&gt;
&lt;p&gt;You have to verify everything. Trust but verify isn&#x27;t optional.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-i-actually-use-it&quot;&gt;How I Actually Use It&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;1-explicit-context&quot;&gt;1. Explicit Context&lt;&#x2F;h3&gt;
&lt;p&gt;I maintain a CONTEXT.md file with my preferences:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Code style (no emoji, wrap at 80 chars, prefer &lt;code&gt;if !&lt;&#x2F;code&gt; over &lt;code&gt;unless&lt;&#x2F;code&gt;)&lt;&#x2F;li&gt;
&lt;li&gt;Project patterns (date-based versioning, git workflow preferences)&lt;&#x2F;li&gt;
&lt;li&gt;Common pitfalls (Ruby openssl gem vs extension, Discourse auth patterns)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This cuts down on back-and-forth. Claude knows I want &lt;code&gt;--no-ff&lt;&#x2F;code&gt; merges without me explaining it every time.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;2-incremental-validation&quot;&gt;2. Incremental Validation&lt;&#x2F;h3&gt;
&lt;p&gt;I don&#x27;t let Claude write 500 lines without checking. Small changes, validate, next change. When it starts going off track, I stop and correct immediately.&lt;&#x2F;p&gt;
&lt;p&gt;If tests fail, I read the error myself. If code looks weird, I ask &quot;why did you do it this way?&quot; and often realize there&#x27;s a better approach.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;3-use-it-for-what-it-s-built-for&quot;&gt;3. Use It For What It&#x27;s Built For&lt;&#x2F;h3&gt;
&lt;p&gt;Good uses:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;File operations (read, edit, search)&lt;&#x2F;li&gt;
&lt;li&gt;Repetitive code changes&lt;&#x2F;li&gt;
&lt;li&gt;Documentation generation&lt;&#x2F;li&gt;
&lt;li&gt;Test script creation&lt;&#x2F;li&gt;
&lt;li&gt;Config file management&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Bad uses:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;Anything requiring judgment calls&lt;&#x2F;li&gt;
&lt;li&gt;Performance optimization without profiling&lt;&#x2F;li&gt;
&lt;li&gt;Security-sensitive code review&lt;&#x2F;li&gt;
&lt;li&gt;&quot;Just make it work&quot; prompts&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h3 id=&quot;4-keep-notes&quot;&gt;4. Keep Notes&lt;&#x2F;h3&gt;
&lt;p&gt;I have Claude maintain daily notes of what we worked on. Not as todo tracking, but as a context refresh. When I come back tomorrow, I can read yesterday&#x27;s notes and pick up where we left off.&lt;&#x2F;p&gt;
&lt;p&gt;The notes also catch when Claude forgets something or contradicts earlier decisions.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-workflow&quot;&gt;The Workflow&lt;&#x2F;h2&gt;
&lt;p&gt;Typical session:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Me&lt;&#x2F;strong&gt;: &quot;I need to test SMTP error logging with mail-relay-simulator&quot;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Claude&lt;&#x2F;strong&gt;: Reads existing code, finds simulator location, proposes script structure&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Me&lt;&#x2F;strong&gt;: &quot;Yeah but make it modular, don&#x27;t hardcode paths&quot;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Claude&lt;&#x2F;strong&gt;: Updates script with env var + path discovery&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Me&lt;&#x2F;strong&gt;: Runs script, hits error&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Claude&lt;&#x2F;strong&gt;: &quot;That error means X, here&#x27;s the fix&quot;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Me&lt;&#x2F;strong&gt;: Applies fix, tests, moves on&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;It&#x27;s not magic. It&#x27;s a very fast junior developer who never gets tired but also never learns from mistakes unless you tell it explicitly.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-trap&quot;&gt;The Trap&lt;&#x2F;h2&gt;
&lt;p&gt;The trap is letting the AI do your thinking. It&#x27;s really easy to just accept the first solution that looks reasonable. But &quot;looks reasonable&quot; and &quot;is correct&quot; aren&#x27;t the same thing.&lt;&#x2F;p&gt;
&lt;p&gt;I caught Claude trying to use &lt;code&gt;Dir.chdir&lt;&#x2F;code&gt; in a script today. RuboCop flagged it as not thread-safe. The &quot;correct&quot; solution was &lt;code&gt;system(..., chdir: path)&lt;&#x2F;code&gt;. Claude didn&#x27;t know that until the linter told it.&lt;&#x2F;p&gt;
&lt;p&gt;If I&#x27;m not reading the code and understanding the changes, I&#x27;m just a very expensive copy-paste machine.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;should-you-use-it&quot;&gt;Should You Use It?&lt;&#x2F;h2&gt;
&lt;p&gt;If you&#x27;re junior: Maybe not yet. You need to build pattern recognition before you can effectively verify AI output. You won&#x27;t know when it&#x27;s bullshitting.&lt;&#x2F;p&gt;
&lt;p&gt;If you&#x27;re mid-level: Useful for grunt work, but keep it on a short leash. You should be reading and understanding every change.&lt;&#x2F;p&gt;
&lt;p&gt;If you&#x27;re senior: This is productivity steroids. You already know what good code looks like. AI just makes it faster to write.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;final-thoughts&quot;&gt;Final Thoughts&lt;&#x2F;h2&gt;
&lt;p&gt;Claude Code isn&#x27;t replacing developers. It&#x27;s replacing the boring parts of development. The parts where you know exactly what needs to happen but it&#x27;s going to take an hour of tedious typing.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m not using less brain power. I&#x27;m using it on the problems that actually matter instead of fighting with test harness boilerplate.&lt;&#x2F;p&gt;
&lt;p&gt;That&#x27;s the win.&lt;&#x2F;p&gt;
</description>
      </item>
    </channel>
</rss>
